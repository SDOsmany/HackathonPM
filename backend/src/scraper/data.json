[
    {
        "url": "https://github.com/DEV-RIOS/SnailAI",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Snail Rendering",
        "award": "BEST OVERALL HACK:",
        "summary": "\"Realtime\" AI imagination for your Rhino model, all within a Rhino viewport, activated via a Display Mode.",
        "content": "# SnailAI\n\n\"Realtime\" AI imagination for your Rhino model, all within a Rhino viewport, activated via a Display Mode.\n\n**SnailAI** was a project developed for the AEC Tech NYC 2024 Hackathon, winning the award for *Best Overall Hack*.\n\n### Team Members\n\n- **Bob Frederick** - RIOS\n- **Jimmy Torres** - RIOS\n- **Oscar Borgstr\u00f6m** - Foster + Partners\n- **Chu Ding, PE, PhD** - RunToSolve\n- **Kohei Hayashi** - Shimizu & CORE studio | Thornton Tomasetti\n- **Sheng Zheng, PE** - Martin/Martin\n- **Kojiro Suzuki** - Shimizu\n- **Yutaka Iribe** - Shimizu\n- **Tamaho Shigemura** - Algorithm Design Lab\n\n### AECTech\nWe wanted to thank CORE Studio for hosting this event. \nHere are the slides we presented at the event. \nhttps://docs.google.com/presentation/d/1IYfWYMRZZFo6tpIs5yYFvRPi0NT_UnSsgiO12qauFYU/edit#slide=id.g2d4d7df7fcd_5_41\n\n\n---\n\n## Setup Instructions\n\n1. **Create a Fal.AI Account**  \n   - Load credits (approximately $5\u2013$10) and import the three included `comfyui` JSON definitions.\n\n2. **Add API Key**  \n   - Create a file named `fal_api_key.txt` located at `\\SnailAI\\Core\\SnailAI\\fal_api_key.txt`, and paste in your Fal.AI API key.\n\n3. **Configure API Endpoint**  \n   - Update the solution to match your specific API endpoint.  \n     - Example: If your endpoint is `\"comfy/DEV-RIOS/snail-rhino-to-turbo\"`, replace \"DEV-RIOS\" with your account name. Ensure endpoint names are accurate as they\u2019re a common point of error.\n\n4. **Build and Install**  \n   - Build the solution and install `SnailAI.rhp` from the `bin` folder.\n\n5. **Import Display Mode**  \n   - Import the included `SnailAI.ini` display mode.\n\n6. **Activate Display Mode**  \n   - In the Rhino viewport, activate the display mode to run the plugin.\n\n---\n\n### Tips for Best Performance\n\n- **Viewport Dimensions**  \n  Render time is highly sensitive to viewport dimensions. For optimal results, try dimensions 768x768 or 1024x1024.\n\n---\n"
    },
    {
        "url": "https://github.com/graphhop",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Graph-Hop",
        "award": "BEST COLLABORATIVE HACK:",
        "summary": "This project is designed to consume Grasshopper files, parse their component data, and store the information in a TinkerPop graph database. This allows for version control and analysis of Grasshopper files.",
        "content": "Graph-Hop\nProject Documentation\nThis Project was initiated as part of the 2024 AECtech Hackathon Organized by Thornton Tomasetti's Core Studio This Project won Best Collaborative Hack.\n\nArchitecture Breakdown\nGraph-Hop (1) Graph-Hop (2) Data model explanation (1)\n\nFront End Overview\nCreate ReactApp\nCall many API\nProfit\nThe frontend uses Typescript+React and React Force Graph for the UI, with Vite for hot reloading.\n\nTo start the frontend server, run the following command to go into the correct directory:\n\ncd graphhop-ui\n\nInstall the necessary dependencies:\n\nnpm run install\n\nThen run the server:\n\nnpm run dev\n\nThe UI will now be running at the specified port.\n\nNote that for the frontend to function properly, you will need a working local Tinkerpop/Gremlin database server running, and a valid OpenAPI key to call to ChatGPT, as we make API calls to these respective servers.\n\nBackEnd Overview\nThis project is designed to consume Grasshopper files, parse their component data, and store the information in a TinkerPop graph database. This allows for version control and analysis of Grasshopper files.\n\nProject Structure\nAI-generated documentation, reference with caution\n\nPluginGrasshopper.csproj\nDescription: This is the project file for the Grasshopper plugin. It includes references to common settings and libraries required for the project.\n\nResponsibilities:\n\nDefines the project configuration, including target framework and dependencies.\nManages build settings and output paths.\nEnsures that all necessary libraries and packages are included for the project to compile and run correctly.\nGremlin.cs\nDescription: This file contains the GremlinConnector class, which is responsible for connecting to the TinkerPop graph database using Gremlin.\n\nResponsibilities:\n\nEstablishes a connection to the TinkerPop graph database.\nProvides methods to begin and commit transactions.\nAdds and retrieves test objects from the graph database.\nAdds nodes to the graph database.\nGraphStrutObject.cs\nDescription: This file contains the GraphStrutObject class, which represents a collection of various nodes related to a graph structure in Rhino.\n\nResponsibilities:\n\nLoads a Grasshopper document and parses its components.\nIterates through document objects to extract component data.\nProcesses connected objects and converts bitmap images to Base64 strings.\nManages the creation of nodes representing component definitions, instances, inputs, and outputs.\nGremlinGeneric.cs\nDescription: This file contains the GremlinGeneric class, which implements the IGremlinGeneric interface.\n\nResponsibilities:\n\nProvides generic methods to interact with the graph database.\nAdds nodes and connections to the graph.\nFinds nodes and checks for the existence of nodes and connections in the graph.\nDigestGHFile.cs\nDescription: This file contains the DigestGHFile class, which is a Rhino command that processes a Grasshopper file.\n\nResponsibilities:\n\nExecutes the command to load and parse a Grasshopper file.\nUses the GraphStrutObject class to extract component data.\nAdds the parsed data to the TinkerPop graph database using the GremlinGeneric class.\nManages the creation and connection of nodes in the graph database.\nCommonVariables.bat\nDescription: This batch file sets up common environment variables used in the project.\n\nResponsibilities:\n\nSets the path to the Visual Studio Developer Command Prompt tools.\nDetermines the path to the yak executable based on the installed version of Rhino.\nSets the name of the solution to build.\nSpecifies the directory where resulting yak packages will be copied.\nExample:\n\n'@echo off\n\nREM VsDevTools might need to be adapted according your installation of Visual Studio set \"VsDevTools=C:\\Program Files\\Microsoft Visual Studio\u00822\\Community\\Common7\\Tools\\VsDevCmd.bat\"\n\nREM where to find yak if exists \"C:\\Program Files\\Rhino 8\\System\\yak.exe\" ( set \"YakExecutable=C:\\Program Files\\Rhino 8\\System\\yak.exe\" ) else ( set \"YakExecutable=C:\\Program Files\\Rhino 7\\System\\yak.exe\" )\n\nREM name of the solution to build set \"Name=PluginTemplate\"\n\nREM where to copy resulting yak packages set \"YakTargetDir=bin\\packages\" '\n\nUsage\nLoading a Grasshopper File\nThe DigestGHFile command is executed in Rhino.\nThe command opens a file dialog to select a Grasshopper file.\nThe selected file is loaded using the GraphStrutObject class.\nThe document objects are iterated and processed to extract component data.\nAdding Data to the Graph Database\nThe parsed component data is added to the TinkerPop graph database using the GremlinGeneric class.\nNodes and connections are created based on the component definitions, instances, inputs, and outputs.\nExample Code\nDigestGHFile.cs\nDetailed Documentation for GraphStrutObject.cs\nClass: GraphStrutObject\nProperties\nComponentDefinitionNodes: A dictionary that stores component definition nodes. Each node contains information about a specific component definition.\nComponentInstanceNodes: A dictionary that stores component instance nodes.\nInputNodes: A dictionary that stores input nodes associated with the GraphStrutObject.\nOutputNodes: A dictionary that stores output nodes in the GraphStrutObject.\nDocumentVersionNode: A node to store document version information.\nDocumentNode: A node to store document information in the GraphHop system.\nPrivate Fields\n_ioDoc: An instance of GH_DocumentIO used to load the Grasshopper document.\n_ghDoc: An instance of GH_Document representing the loaded Grasshopper document.\n_xmlDoc: An instance of XmlDocument representing the XML representation of the Grasshopper document.\n_versionId: A Guid representing the version ID of the document.\nMethods\nLoadDocument\npublic bool LoadDocument(string filePath, out string errmsg) Description: Loads a Grasshopper document from the specified file path.\n\nParameters:\n\nfilePath: The path to the Grasshopper file.\nerrmsg: An output parameter that returns an error message if the document fails to load.\nReturns: true if the document is loaded successfully; otherwise, false.\n\nIterateDocumentObjects\npublic void IterateDocumentObjects()\n\nDescription: Iterates through all document objects and processes them.\n\nGetConnectedObjects\npublic void GetConnectedObjects(IGH_DocumentObject obj, ComponentInstanceNode componentInstanceNode)\n\nDescription: Processes the connected objects (inputs and outputs) of a given document object.\n\nParameters:\n\nobj: The document object to process.\ncomponentInstanceNode: The component instance node to update.\nPopulateDocumentProperties\nprivate void PopulateDocumentProperties() Description: Populates the properties of the document node.\n\nPopulateDocumentObjectProperties\npublic ComponentInstanceNode PopulateDocumentObjectProperties(IGH_DocumentObject obj) Description: Populates the properties of a document object and returns a component instance node.\n\nParameters:\n\nobj: The document object to process.\nReturns: The populated component instance node.\n\nProcessInput\nprivate void ProcessInput(IGH_Param source, ComponentInstanceNode componentInstanceNode) Description: Processes an input source and updates the component instance node.\n\nParameters:\n\nsource: The input source to process.\ncomponentInstanceNode: The component instance node to update.\nProcessOutput\nprivate void ProcessOutput(IGH_Param recipient, ComponentInstanceNode componentInstanceNode) Description: Processes an output recipient and updates the component instance node.\n\nParameters:\n\nrecipient: The output recipient to process.\ncomponentInstanceNode: The component instance node to update.\nConvertBitmapToBase64\nprivate string ConvertBitmapToBase64(Bitmap bitmap) Description: Converts a Bitmap image to a Base64 string.\n\nParameters:\n\nbitmap: The Bitmap image to convert.\nReturns: The Base64 string representation of the Bitmap image.\n\nReferenced Structures\nComponentDefinitionNode\nDescription: Represents a node containing information about a specific component definition.\n\nProperties:\n\nComponentGuid: The unique identifier of the component.\nName: The name of the component.\nDescription: The description of the component.\nIcon: The Base64 string representation of the component's icon.\nComponentInstanceNode\nDescription: Represents a node containing information about a specific component instance.\n\nProperties:\n\nInstanceGuid: The unique identifier of the instance.\nComponentGuid: The unique identifier of the component.\nNickName: The nickname of the instance.\nX: The X-coordinate of the instance's position.\nY: The Y-coordinate of the instance's position.\nInputs: A list of input node GUIDs.\nOutputs: A list of output node GUIDs.\nXmlRepresentation: The XML representation of the instance.\nDataInputNode\nDescription: Represents a node containing information about an input connection.\n\nProperties:\n\nTargetGuid: The unique identifier of the target node.\nInstanceGuid: The unique identifier of the input instance.\nNickName: The nickname of the input.\nName: The name of the input.\nDataOutputNode\nDescription: Represents a node containing information about an output connection.\n\nProperties:\n\nTargetGuid: The unique identifier of the target node.\nInstanceGuid: The unique identifier of the output instance.\nNickName: The nickname of the output.\nName: The name of the output.\nDocumentVersionNode\nDescription: Represents a node containing information about the document version.\n\nProperties:\n\nVersionId: The unique identifier of the document version.\nDocumentNode\nDescription: Represents a node containing information about the document.\n\nProperties:\n\nDocumentID: The unique identifier of the document.\nDisplayName: The display name of the document.\nFilePath: The file path of the document.\nOwner: The owner of the document.\nDocumentHeadersXml: The XML representation of the document headers.\nDefinitionPropertiesXml: The XML representation of the definition properties.\nRcpLayoutXml: The XML representation of the RCP layout.\nGHALibrariesXml: The XML representation of the GHA libraries."
    },
    {
        "url": "https://github.com/ssajedi/upzone",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "UpZone",
        "award": "BEST BREAKOUT TEAM & HACKER'S CHOICE:",
        "summary": "UpZone is your one-click solution to modeling your NYC lot's buildable zoning volume. The app searches multi-thousand-page zoning resolution documents and city websites, identifies relevant zoning requirements, and generates a user-friendly 3D model for architects to hit the ground running with design. Developed by a diverse team of architects, software developers, machine learning engineers, computational designers, and structural engineers. It combines large language models with spatial algorithms to turn complex, interconnected data into a clean, legible 3D model.",
        "content": "<img src=\"https://github.com/ssajedi/upzone/blob/main/assets/logo.png\" width=\"300\">\n\n\n# UPZONE\nUpZone is your one-click solution to modeling your NYC lot's buildable zoning volume. \n\nPrototyped in NYC in 24 hours, the app searches multi-thousand-page zoning resolution documents and city websites, identifies relevant zoning requirements, and generates a user-friendly 3D model for architects to hit the ground running with design. \n\nUpZone is an app developed during the 2024 [AECTech Hackathon](https://www.aectech.us/nyc-conference) by a diverse team of architects, software developers, machine learning engineers, computational designers, and structural engineers. It combines large language models with spatial algorithms to turn complex and interconnected data into a clean, legible 3D model.\n\n![Alt Text](assets/gdemo.gif)\n\n# Prerequisites\nIn order to use UPZone, you will need:\n* A free [Shapediver](https://www.shapediver.com/) account\n* An [OpenAI API key](https://platform.openai.com/)\n\n\n# Zone parameters \nThe team experimented with two methods to extract the following parameters:\n* Setback: front, rear, and side\n* Sky exposure angle\n* Height limit\n* Maximum height for front yard line\n\n## ChatGPT (method 1)\nWe utilized [Swiftlet](https://www.food4rhino.com/en/app/swiftlet) to call the ChatGPT API and extract these values from the LLM. Please refer to the grasshopper definition for further details on how prompt engineering was done. \n\n## Web search + Gemini experiment (method 2)\nWe utilized a python library to perform search using [DuckDuckGo library](https://pypi.org/project/duckduckgo-search/) and scrape web for the required values. The inputs were then fed to Google Geimini Flash 1.5. \n\n  \n# Grasshopper Plugin\nIn order to process to geometries, you will need:\n* Rhino 7 or 8\n* The [Swiftlet](https://www.food4rhino.com/en/app/swiftlet) plugin for grasshopper\n* [Lot](https://github.com/ssajedi/upzone/blob/main/geojson/lotGeometries.geojson) geometry data\n* [Building Footprint](https://github.com/ssajedi/upzone/blob/main/geojson/lotGeometries.geojson) geometry data\n\nThe raw data was processed in QGIS to obtain the subset GeoJSON, which is then converted to Grasshopper polylines using our custom C# component. However, there is an option in the grasshopper script that allows you to make an API call if the data is available as a geoJSON.\n\nData source:\n* Lot geometries: [MapPLUTO - Shoreline Clipped (Shapefile)](https://www.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page). \n* Building geometries: [Building Footprints from NYC Opendata](https://data.cityofnewyork.us/Housing-Development/Building-Footprints/nqwf-w8eh). \n\n# Team Members\n\n| Name                                   | Company                        |\n|----------------------------------------|--------------------------------|\n| **Anish Reddy**                        | Perkins & Will                 | \n| **Eddy Lopez**                         | LPA                            |\n| **Elcin Ertugrul**                     | Thornton Tomasetti (CORE)      |\n| **Georgios Athanasopoulos**            | Thornton Tomasetti (CORE)      |\n| **Jari Prachasartta**                  | KPF                            |\n| **Jihoon Park**                        | Walter P Moore                 |\n| **Joyce Hanlon**                       | Sn\u00f8hetta                       |\n| **Mahsa Dehghani**                     | Memo Studio & Corgan           |\n| **Omid Sajedi**                        | Thornton Tomasetti (CORE)      |\n| **Susanna van de Graaf**               | Thronton Tomasetti             |\n"
    },
    {
        "url": "https://github.com/team-speckle-automation/SPLASH",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Splash",
        "award": "No Award Found",
        "summary": "This project aims to streamline model analysis and enhance feedback processes for AEC projects. By integrating Speckle, we provide stakeholders easy web-based access to 3D model analysis results that update in real-time!. This setup empowers non-technical stakeholders to review analysis outputs and provide feedback directly, without needing specialized software like Revit or Rhino.",
        "content": "<a href=\"https://github.com/team-speckle-automation/SPLASH\">\n    <img src=\"https://github.com/team-speckle-automation/SPLASH/blob/main/Assets/Splash_logo.png\" alt=\"SPLASH Logo\" width=\"200\" height=\"200\">\n</a>\n\n## Project Overview\nSPLASH! is a project created for **AEC Tech Hackathon 2024** in New York.\nThis project aims to streamline model analysis and enhance feedback processes for AEC projects. By integrating Speckle, we provide stakeholders easy web-based access to 3D model analysis results that **update in real-time!**.\n\nThis setup empowers non-technical stakeholders to review analysis outputs and provide feedback directly, without needing specialized software like Revit or Rhino.\n### What Pain Points Are We Solving?\n- **Collaborative Analysis**: Enable stakeholders to view and interact directly with the analysis results in 3D pushed to Speckle.\n- **Automated Updates**: Changes made in Revit trigger updates on Speckle, automatically performing analyses via Speckle Automate.\n- **Visual Feedback**: Provide intuitive, color-coded geometry in the Speckle viewer, streamlining feedback loops.\n- **Flexible Analysis**: Integrates Karamba3D within Grasshopper for customizable structural analysis, adaptable for various project needs (e.g., structural, sustainability).\n## Technologies & Tools\n- **Speckle**: Data exchange platform for AEC projects.\n- **Revit**: BIM software with Speckle connector.\n- **Grasshopper**: Visual programming for parametric design.\n- **Grasshopper plugins:** like Karamba3D or Ladybug for design analysis.\n## Getting Started :rocket:\n### Prerequisites\n   - **Speckle Account**: Required for accessing Speckle's platform.\n   - **Speckle Revit Connector**: Enables models to be pushed from Revit to Speckle. [Speckle Manager](https://speckle.guide/#speckle-manager)\n   - **Grasshopper Analysis Scripts**: Used for analyzing model updates and triggering automated analysis.\n\n### Setup Instructions\n1. **Create a Speckle Project**: [Speckle Setup Guide](https://speckle.guide/workspaces/projects.html)\n2. **Export Revit Model to Speckle**: Use the Speckle Revit **Connector** to send your model to Speckle.\n  - Optionally, set up **Speckle Scheduler** to automate sending upon syncing/saving.\n4. **Configure Analysis**: Set up Grasshopper with Karamba3D to run the desired analysis automatically when syncing/saving from Revit.\n5. **View and Provide Feedback**: Go to your online Speckle project viewer to review results and leave feedback.\n## :movie_camera: Demo\nHere is a GIF walkthrough illustrating each step, from model sync to viewing analysis results. You can find more [here](https://github.com/team-speckle-automation/SPLASH/tree/main/Demos)\n\n![Demo](https://github.com/team-speckle-automation/SPLASH/blob/main/Demos/Speckle_Composite_Analysis.gif)\n\n[Speckle Project](https://app.speckle.systems/projects/0a088653cb/models/05fb82a423)\n\n[Presentation here](https://github.com/team-speckle-automation/SPLASH/blob/main/Presentation/Splash_AECtech2024NYC.pdf)\n## :crystal_ball: Future Work\n- **Power BI Integration**: Expand data visualization with Power BI dashboards.\n- **Expanded Analysis Capabilities**: Extend Speckle Compute to support more complex analyses.\n---\n## :busts_in_silhouette: Team\n   - **Agustina Aboy** [@agusaboy](https://github.com/agusaboy)\n   - **Anik Alam** \n   - **Erika Santos** [@erikasantosrocha](https://github.com/erikasantosrocha)\n   - **Julio Sarachaga** [@julillosamaral](https://github.com/ulillosamaral)\n   - **Kent Pretorius** \n   - **Laszlo Andrasi**\n   - **Nathan Terranova** [@nterranova](https://github.com/nterranova)\n   - **Stephen Prendergast** [@sgcprender](https://github.com/sgcprender)\n   - **Wade Vollink** [@Wizard-Wade](https://github.com/Wizard-Wade)\n\nProof We Were Here: [Photos from the Hackathon](https://github.com/team-speckle-automation/AECTech2024/tree/main/Photos)\n"
    },
    {
        "url": "https://github.com/murra133/EarthToRhino",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Earth to Rhino",
        "award": "No Award Found",
        "summary": "EarthToRhino is a bridge between Cesium, a 3d Geospatial platform, and McNeel's Rhinoceros 3D through Grasshopper.",
        "content": "# EarthToRhino\n\n![Rhino Spacesuit](/Assets/Rhino%20Spacesuit_Short.gif)\n\n## What is Earth To Rhino\nEarthToRhino is a bridge between Cesium, a 3d Geospatial platform \ud83c\udf0e, and McNeel's Rhinoceros 3D \ud83e\udd8f through Grasshopper \ud83e\udd97. This was developed during the 2024 AEC Tech hackathon hosted by CORE studio at Thornton Tomasetti.\n\n# Team members \ud83d\udc68\u200d\ud83d\ude80\ud83d\udc69\u200d\ud83d\ude80\n- Paris Nikitidis\n- Sergey Pigach\n- Alfredo Chavez\n- Quoc Dang\n- Joanna Sabak\n- Weiting Kong\n- Jeroen Janssen\n- Brian Murray\n- Nico Azel\n- Jason Yang\n\n## Architecture\n![Architecture](Assets/Architecture.gif)\n\n```\n     +--------------+       +-------------------------------+                           \n     |Cesium Schema |       |      Grasshopper Plugin       |                           \n     +------+-------+       +---------------+---------------+                           \n            |                               |                                           \n            |                               |                                           \n            |               +-------------------------------+                           \n     +--------------+       |     Geolocation mapping       |                           \n     |              |       |                               |       +--------------+    \n     |     glTF     |-------|  3D Tiles Download REST API   |-------|  Rhinoceros  |    \n     |              |       |                               |       +--------------+    \n     +--------------+       | Convert to Rhino Mesh. Custom |                           \n                            +-------------------------------+                           \n```\n\n## Prerequisites\n- Rhino 8\n- Cesium API Key\n\n## Installation\nGet it through the Package Manager! Search for Earth To Rhino and press install.\n\nor... install through the source code:\n\n1. Install package by running:\n```\n$ git clone https://github.com/murra133/EarthToRhino.git\n```\n2. Open Solution in Visual Studio\n3. Build Solution to create \"Earth To Rhino\" Components\n4. You will need a Google Developer Account. Enable that here: [Google Developer Account](https://developers.google.com/maps).\n5. Once active, you will get an API key, which you'll need to download the tiles. Copy the API key and save somewhere save on your hard disk.\n6. The Google Map Tiles API needs to be enabled separately. You can do that here: [Map Tiles API](https://console.developers.google.com/apis/api/tile.googleapis.com/overview?).\n\n## Acknowledgements \ud83d\ude4c\n\nA huge thanks to AEC Tech 2024 for arranging and hosting this event.\nPlease check out other hackathon projects and future hackathon events \ud83d\udc69\u200d\ud83d\udcbb hosted by [AECTech](https://www.aectech.us/).\n\n## Licensing \ud83d\udd11\n\nDistributed under the MIT license. See `LICENSE` for more information.\n\nThis application utilizes the Google Map Tiles API. By using this application you are bound to their [Terms of Use](https://cloud.google.com/maps-platform/terms)\nand their [Privacy Policy](https://policies.google.com/privacy).\n\n![Floating in Space](/Assets/Floating_in_Space.gif)\n"
    },
    {
        "url": "https://github.com/lukegehron/NLP-to-3DBuildings",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "D-AI-LOG",
        "award": "No Award Found",
        "summary": "This project demonstrates how to create a FastAPI-based API that interacts with an OpenAI assistant. The API allows you to retrieve the assistant, send messages, and receive responses, all using OpenAI's Assistant and Thread APIs. It receives instructions to generate a building and returns the building description in a JSON format.",
        "content": "# \ud83e\udd96 NLP-to-3DBuildings\n\nAn expansion of a 3D parametric modeling playground created for [AEC Tech 2024], focused on generating BIM models from natural language. Imagine combining Figma with large language models (LLMs), but specifically designed for Building Information Modeling (BIM).\n\n## \u2728 Features\n\n- \ud83e\udd1d Real-time collaborative 3D modeling\n- \ud83e\uddf1 Parametric components with live updates\n- \ud83c\udfa8 Interactive transform controls\n- \ud83d\udd0d Command palette for quick actions\n- \ud83d\udc65 Multi-user presence and interaction\n- \ud83c\udfae Orthographic and perspective camera modes\n- \ud83d\udc65 Tag @ai whenever you want to involve LLM in design process\n\n## \ud83d\ude80 Quick Start\n\n```bash\n# Clone the frontend repository\ngit clone github.com/lukegehron/NLP-to-3DBuildings\n\n# Clone the backend repository\nBackend: github.com/franmaranchello/llmto3d-backend\n\n# Clone the UNITY repository\nUnity: github.com/franmaranchello/llmto3d-geoengine\n\n# Install dependencies (for frontend)\ncd NLP-to-3DBuildings\nnpm install\n\n# Start the development server (for frontend)\nnpm run dev\n```\n\nVisit `http://localhost:5173` to see your local instance.\n\n## \ud83d\udee0\ufe0f Tech Stack\n\n- **Frontend Framework**: React\n- **3D Graphics**: React Three Fiber + Three.js\n- **Multiplayer**: Liveblocks\n- **Styling**: Tailwind CSS\n- **UI Components**: shadcn/ui\n\n## \ud83c\udfd7\ufe0f Architecture\n\nBuildosaur is built on four core principles:\n\n1. **Composable 3D Graphics**: Using React Three Fiber for declarative 3D rendering, we can create complex 3D scenes using familiar React patterns. Components are built as pure functions that can be easily composed and reused.\n\n2. **Real-time Collaboration**: Powered by Liveblocks, the application maintains a synchronized state across all connected clients. The collaboration system handles presence, cursors, and real-time updates to the 3D model with minimal configuration. It allows users to tag @ai LLM model to provide requested geometry input.\n\n3. **Extensible Component System**: A custom component registry allows for easy addition of new parametric elements. Each component is self-contained with its own controls and update logic, making the system highly extensible.\n\n4. **Simple Deployment**: For workshop purposes, the application is designed as a single-page application (SPA) hosted on GitHub Pages. This eliminates the need for complex backend infrastructure while still providing full collaborative functionality through Liveblocks.\n\n## \ud83e\udde9 Creating Custom Components\n\n```jsx\n// Example component definition\nconst boxDefinition = {\n  component: \"Box\",\n  geometry: {\n    type: \"BoxGeometry\",\n    args: [\"width\", \"height\", \"length\"],\n  },\n  material: {\n    type: \"MeshStandardMaterial\",\n    props: {\n      color: \"color\",\n    },\n  },\n  controls: {\n    dimensions: {\n      width: { value: 1, min: 0.1, max: 10, step: 0.1 },\n      height: { value: 1, min: 0.1, max: 10, step: 0.1 },\n      length: { value: 1, min: 0.1, max: 20, step: 0.1 },\n      scale: { value: 1 },\n    },\n    appearance: {\n      color: { value: \"orange\" },\n    },\n  },\n  defaultProps: {\n    width: 1,\n    height: 1,\n    length: 1,\n    scale: 2,\n    color: \"orange\",\n  },\n};\n```\n\n## \ud83c\udf1f Motivation\n\nBuilt for AEC Tech 2024, NLP-to-3DBuildings demonstrates how modern web technologies make it easier than ever to create:\n\n- **Shareable, composable, reactive 3D graphics** using React and React Three Fiber\n- **Real-time collaborative experiences** using tools like Liveblocks\n- **Rich, interactive interfaces** with modern UI frameworks\n- **Smart interaction with AI** through a chatbox\n\n## \ud83d\udcdd Workshop Context\n\nThis project is extention of the \"Figma for BIM in an Afternoon\" workshop Hack at AEC Tech 2024, hosted by Thornton Tomasetti. This project explores capabilities of current LLM models to assist in creating BIM models\n\n## \ud83e\udd1d Contributing\n\nContributions are welcome. To contribute:\n\n1. Fork the repository\n2. Create a feature branch\n3. Submit a pull request\n\n## \ud83d\udcc4 License\n\nMIT \u00a9 Nicolas Schmidt, D-AI-LOG Team 2024\n\n---\n\nBuilt with \u2764\ufe0f for AEC Tech 2024\n"
    },
    {
        "url": "https://github.com/v-machine/Nolli-Cannolli",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Nolli Cannolli",
        "award": "No Award Found",
        "summary": "N-C is a project that fine-tunes a diffusion model on Nolli maps to easily generate baseline geometry with diverse urban form. The model creates images that hybridize the urban fabric from any city and can be adapted to a specific site boundary. These images feed into a Grasshopper script to generate 3d massing with customizable density.",
        "content": "# Nolli-Cannolli\n\nN-C is a project that fine-tunes a diffusion model on Nolli maps to easily generate baseline geometry with diverse urban form. \n\nThe model creates images that hybridize the urban fabric from any city and can be adapted to a specific site boundary. These images feed into a Grasshopper script to generate 3d massing with customizable density.\n\n## Milestones:\n\n- [x] 3,400 Nolli Map Dataset Generated (ArcGIS)\n\n- [x] Early LLM Nolli Description/Labeling (Manual/Claude)\n\n- [x] Lora, CNN+LLM, Dreambooth fine-tuning explored\n\n- [x] Fine-tuned 2 Stable Diffusion v2 Models\n\n- [x] Bitmaps to 3D Forms in Grasshopper C#\n\n- [x] Shape Diver UI\n\n- [x] Presentation Deck\n"
    },
    {
        "url": "https://github.com/Kyungho0511/3d-scan-with-spatial-analysis/tree/ms_pythonCode",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "From AEC to your HOME!",
        "award": "No Award Found",
        "summary": "Tools for preprocessing point clouds for analysis in Grasshopper using Ladybug and for web visualization with React and Three.js. The preprocessing pipeline cleans, transforms, and prepares spatial data, making it compatible with computational design workflows and interactive 3D visualization.",
        "content": "\n# Point Cloud Preprocessing for Grasshopper, Ladybug, and Web Visualization\n\nThis repository provides tools for preprocessing point clouds for analysis in Grasshopper using Ladybug and for web visualization with React and Three.js. The preprocessing pipeline cleans, transforms, and prepares spatial data, making it compatible with computational design workflows and interactive 3D visualization.\n\n![png](https://github.com/user-attachments/assets/3ccf5d4d-3799-46a2-a19d-80563a91013d)\n\n\n## Table of Contents\n- [Overview](#overview)\n- [Features](#features)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Preprocessing Details](#preprocessing-details)\n- [Visualization Workflow](#visualization-workflow)\n- [Dataset License](#dataset-license)\n- [Contributing](#contributing)\n\n\n## Overview\n\nThis repository offers a Python-based toolset to preprocess point cloud data, making it ready for environmental analysis with Ladybug in Grasshopper and for interactive 3D web-based applications using React and Three.js. The provided scripts handle data transformation, segmentation, and spatial analysis, facilitating seamless integration between 3D point clouds and analytical workflows.\n\n## Features\n\n- **Load and Preprocess Point Clouds**: Import point cloud data from files (e.g., `.parquet`) and transform the data for further analysis.\n- **Spatial Analysis**: Extract floors, ceilings, and windows from point cloud data for precise height calculations and boundary detection.\n- **Transformation and Scaling**: Scale and pad point cloud data for image representation and contour detection.\n- **Contour Extraction**: Use Canny edge detection and contour approximation for identifying structural boundaries.\n- **Data Export**: Transform data back to its original scale and format for compatibility with Grasshopper and Ladybug.\n\n## Installation\n\n1. **Clone the repository:**\n    \\`\\`\\`bash\n    git clone https://github.com/yourusername/point-cloud-preprocessor.git\n    cd point-cloud-preprocessor\n    \\`\\`\\`\n\n2. **Install Python dependencies:**\n    \\`\\`\\`bash\n    pip install numpy pandas opencv-python matplotlib pyarrow\n    \\`\\`\\`\n\n3. **Optional: Install additional visualization tools for web integration**\n    - For the React-based web visualization:\n      \\`\\`\\`bash\n      cd web-visualization\n      npm install\n      \\`\\`\\`\n\n## Usage\n\n### Preprocessing Workflow\n\n1. **Prepare Your Point Cloud Data:**\n   - Ensure your point cloud data is saved as a `.parquet` file.\n   - Place the file in the `data/` directory.\n\n2. **Run the Preprocessing Script:**\n   \\`\\`\\`bash\n   python preprocess.py --input data/your-pointcloud-file.parquet\n   \\`\\`\\`\n   - This script will:\n     - Load the point cloud data.\n     - Extract floor, ceiling, and window data.\n     - Transform and normalize coordinates for further analysis.\n     - Identify and approximate room boundaries.\n     - Output transformed coordinates and metadata.\n\n3. **Data Output:**\n   - The script returns processed data including:\n     - `final_fp`: The contour points representing the room boundary.\n     - `room_height`: A list with the minimum and maximum height of the room.\n     - `final_endpoint_lst`: The endpoints of window alignments.\n     - `z_bound`: The `z`-boundaries of window groups.\n\n### Preprocessing Details\n\nThe \\`preprocess.py\\` script includes functions for various preprocessing steps:\n- **Data Loading**: Reads point cloud data from a `.parquet` file.\n- **Point Extraction**: Extracts points based on categories (e.g., ceiling, floor, windows).\n- **Transformation**: Normalizes point positions to fit within a specified image size for visualization.\n- **Edge Detection and Contour Approximation**: Identifies room boundaries using OpenCV's edge detection and contour approximation methods.\n- **Reverse Transformation**: Transforms points back to their original scale for compatibility with Grasshopper.\n\n### Visualization Workflow\n\n1. **Prepare Data for Web Visualization:**\n   - Export the processed point cloud data from the script as a JSON or CSV file.\n   - Place the exported file in the \\`web-visualization/public/data/\\` directory.\n\n2. **Start the React Application:**\n   \\`\\`\\`bash\n   cd web-visualization\n   npm start\n   \\`\\`\\`\n   - Open \\`http://localhost:3000\\` to view the 3D visualization of your point cloud data.\n\n3. **Deploy the Application**: \n   - Use platforms like Vercel or Netlify for deployment.\n   - Adjust paths in the React app if needed.\n\n## Dataset License\nThe InLUT dataset is licensed under the [Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/legalcode).\n\n\n## Contributing\n\nWe welcome contributions! Please see our [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on how to contribute to this project.\n\n\n\n"
    },
    {
        "url": "https://github.com/jacksonjunelee/AEC_Hackathon_qrkiller",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "IMPRINT",
        "award": "No Award Found",
        "summary": "The \"Imprint\" project presents a solution to replace QR codes with embedded, design-integrated visual links. Criticizing QR codes as disruptive and unreadable, it utilizes computer vision and image segmentation across platforms like web frontends, device frontends, and a Revit add-in to embed information directly within images. By generating data embeddings from processed images and employing techniques like image augmentation and feature extraction, Imprint enables drawings and photos to function as interactive, linkable elements\u2014eliminating the need for traditional QR codes.",
        "content": "# Imprint (AEC Hackathon)\nThe \"Imprint\" project presents a solution to replace QR codes with embedded, design-integrated visual links. Criticizing QR codes as disruptive and unreadable, it utilizes computer vision and image segmentation across platforms like web frontends, device frontends, and a Revit add-in to embed information directly within images. By generating data embeddings from processed images and employing techniques like image augmentation and feature extraction, Imprint enables drawings and photos to function as interactive, linkable elements\u2014eliminating the need for traditional QR codes.\n"
    },
    {
        "url": "https://github.com/SHL-Digital-Practice/eq-backend",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "EQUALIZER",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "<p align=\"center\">\n  <a href=\"http://nestjs.com/\" target=\"blank\"><img src=\"https://nestjs.com/img/logo-small.svg\" width=\"200\" alt=\"Nest Logo\" /></a>\n</p>\n\n[circleci-image]: https://img.shields.io/circleci/build/github/nestjs/nest/master?token=abc123def456\n[circleci-url]: https://circleci.com/gh/nestjs/nest\n\n  <p align=\"center\">A progressive <a href=\"http://nodejs.org\" target=\"_blank\">Node.js</a> framework for building efficient and scalable server-side applications.</p>\n    <p align=\"center\">\n<a href=\"https://www.npmjs.com/~nestjscore\" target=\"_blank\"><img src=\"https://img.shields.io/npm/v/@nestjs/core.svg\" alt=\"NPM Version\" /></a>\n<a href=\"https://www.npmjs.com/~nestjscore\" target=\"_blank\"><img src=\"https://img.shields.io/npm/l/@nestjs/core.svg\" alt=\"Package License\" /></a>\n<a href=\"https://www.npmjs.com/~nestjscore\" target=\"_blank\"><img src=\"https://img.shields.io/npm/dm/@nestjs/common.svg\" alt=\"NPM Downloads\" /></a>\n<a href=\"https://circleci.com/gh/nestjs/nest\" target=\"_blank\"><img src=\"https://img.shields.io/circleci/build/github/nestjs/nest/master\" alt=\"CircleCI\" /></a>\n<a href=\"https://coveralls.io/github/nestjs/nest?branch=master\" target=\"_blank\"><img src=\"https://coveralls.io/repos/github/nestjs/nest/badge.svg?branch=master#9\" alt=\"Coverage\" /></a>\n<a href=\"https://discord.gg/G7Qnnhy\" target=\"_blank\"><img src=\"https://img.shields.io/badge/discord-online-brightgreen.svg\" alt=\"Discord\"/></a>\n<a href=\"https://opencollective.com/nest#backer\" target=\"_blank\"><img src=\"https://opencollective.com/nest/backers/badge.svg\" alt=\"Backers on Open Collective\" /></a>\n<a href=\"https://opencollective.com/nest#sponsor\" target=\"_blank\"><img src=\"https://opencollective.com/nest/sponsors/badge.svg\" alt=\"Sponsors on Open Collective\" /></a>\n  <a href=\"https://paypal.me/kamilmysliwiec\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Donate-PayPal-ff3f59.svg\"/></a>\n    <a href=\"https://opencollective.com/nest#sponsor\"  target=\"_blank\"><img src=\"https://img.shields.io/badge/Support%20us-Open%20Collective-41B883.svg\" alt=\"Support us\"></a>\n  <a href=\"https://twitter.com/nestframework\" target=\"_blank\"><img src=\"https://img.shields.io/twitter/follow/nestframework.svg?style=social&label=Follow\"></a>\n</p>\n  <!--[![Backers on Open Collective](https://opencollective.com/nest/backers/badge.svg)](https://opencollective.com/nest#backer)\n  [![Sponsors on Open Collective](https://opencollective.com/nest/sponsors/badge.svg)](https://opencollective.com/nest#sponsor)-->\n\n## Description\n\n[Nest](https://github.com/nestjs/nest) framework TypeScript starter repository.\n\n## Installation\n\n```bash\n$ pnpm install\n```\n\n## Running the app\n\n```bash\n# development\n$ pnpm run start\n\n# watch mode\n$ pnpm run start:dev\n\n# production mode\n$ pnpm run start:prod\n```\n\n## Test\n\n```bash\n# unit tests\n$ pnpm run test\n\n# e2e tests\n$ pnpm run test:e2e\n\n# test coverage\n$ pnpm run test:cov\n```\n\n## Support\n\nNest is an MIT-licensed open source project. It can grow thanks to the sponsors and support by the amazing backers. If you'd like to join them, please [read more here](https://docs.nestjs.com/support).\n\n## Stay in touch\n\n- Author - [Kamil My\u015bliwiec](https://kamilmysliwiec.com)\n- Website - [https://nestjs.com](https://nestjs.com/)\n- Twitter - [@nestframework](https://twitter.com/nestframework)\n\n## License\n\nNest is [MIT licensed](LICENSE).\n"
    },
    {
        "url": "https://github.com/ssajedi/FAM-JAM",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "FAM JAM",
        "award": "BEST OVERALL HACK:",
        "summary": "FAM JAM is a Revit Plugin developed during the 2024 AECTech Hackathon. We created a solution aimed at simplifying specification sheet management for Revit, targeting architectural workflows. Fam Jam allows users to seamlessly integrate Revit families with specification sheets, addressing a common bottleneck by turning families into specs, making the process more intuitive and efficient.",
        "content": "<img src=\"https://github.com/ssajedi/FAM-JAM/blob/main/assets/Logo.svg\" width=\"300\">\n\n# FAM JAM\n**Intelligent Spec Management for Revit**\n\nFAM JAM is a Revit Plugin developed during the 2024 [AECTech Hackathon](https://www.aectech.us/la-event). We created a solution aimed at simplifying specification sheet management for Revit, targeting architectural workflows. Fam Jam allows users to seamlessly integrate Revit families with specification sheets, addressing a common bottleneck by turning families into specs, making the process more intuitive and efficient. \n\n# Prerequisites\nIn order to use FAM JAM, you will require:\n* Revit\n* [OpenAI API key](https://platform.openai.com/)\n  \n# Getting Started\nTo use this repository please follow these steps:\n* Clone the repository using <git>\n* Create an OpenAI API key\n* Create secret.txt and add the API Key.\n* Place secret.txt inside the main project directory. \n* [To be added by Frank]\n\n# Demo \nPlease refer to the following video for a demonstration of how FAM JAM.\n\n# Future work\nFor future work, we are focusing on several key areas of development to enhance system performance and usability even further:\n\n* Further expansion of the .rfa family database\n* Enhanced prompting mechanisms: The API usage costs can potentially be reduced by optimized the image resolutions in the API requests. \n* AI-driven insights for asset selection: We plan to adopt an AI semantic search feature in the workflow, allowing for even smarter asset selection and flitering.\n* Improved credential management: Upcoming improvements will include more sophisticated security protocols and user-friendly interfaces for managing credentials\n\n# Team\n\n| ![Nehansh Saxena](https://github.com/ssajedi/FAM-JAM/blob/main/assets/nehansh.jpg) | ![Frank(Xu) Li](https://github.com/ssajedi/FAM-JAM/blob/main/assets/Frank.jpg) | ![Seyedomid Sajedi](https://github.com/ssajedi/FAM-JAM/blob/main/assets/Omid.jpg) |\n|:--:|:--:|:--:|\n| [**Nehansh Saxena**](https://www.linkedin.com/in/nehansh-saxena-leed-ga-assoc-aia-137982127/) | [**Frank(Xu) Li**](https://www.linkedin.com/in/frankeng/) | [**Seyedomid Sajedi**](https://www.linkedin.com/in/seyedomid-sajedi-263b703a/) |\n| Architectural Designer<br>S/L/A/M Collaborative<br>Los Angeles, CA | Senior Project Engineer<br>Saiful Bouquet<br>Irvine, CA | Associate AI/ML Engineer<br>Thornton Tomasetti<br>NYC, NY |\n\n"
    },
    {
        "url": "https://github.com/CruisingCtrl/AECroom107",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Auto Park",
        "award": "No Award Found",
        "summary": "Auto Park is a study that aims to streamline the parking lot design process by automating 3D model generation using client-provided 2D data.",
        "content": null
    },
    {
        "url": "https://github.com/AGranosik/TheCanvas",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "C",
        "award": "BEST OVERALL HACK:",
        "summary": "A sharable analysis application where designers push models and analysis from RHINO Software to Speckle. Speckle's new Automate picks up the model for further analysis and then the designer can browse, inspect and share direct links with stakeholders the results on a simple web page, no login required.",
        "content": "# TheCanvas\n\nWeb C'applicattion \n\n## Setup \n\n### Backend\n\nStep neccessary to setup:\n\n```docker-compose build```\n\n```docker-compose up -d``` \n\n\nBackend will be exposed on -> 7167\n\n### Frontend \n\nGo into : ./Frontend\n\n``` npm install```\n\n``` npm run dev```\n\n"
    },
    {
        "url": "https://github.com/EdShapeDiver/CoffeeBridges",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Bridges for Coffee",
        "award": "BEST COLLABORATIVE HACK:",
        "summary": "From just 2 points on a map to a 3d-printable bridge concept with design and production models, AI-enabled rendering and documentation in PDF. All so that you can get to your morning coffee faster",
        "content": "# VIKTOR template for codespaces\nThis template serves as a quickstart to start developing VIKTOR applications.\n\nPlease consult the [cloud-based development guide](https://docs.viktor.ai/docs/getting-started/installation/remote-development/) for a detailed explanation on how to setup your codespace.\n\nShapediver models\n- https://www.shapediver.com/app/m/aec-tech-barcelona-hackaton-get-route-data\n- https://www.shapediver.com/app/m/aec-tech-barcelona-hackaton-bridge-toolpath\n- https://www.shapediver.com/app/m/aec-tech-barcelona-hackaton-bridge\n"
    },
    {
        "url": "https://github.com/peng-an-chen/aectech-hackathon-2024-tag-it",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Tag It",
        "award": "BEST OPEN SOURCE HACK:",
        "summary": "Real time markups from PDF to BIM. Improving markups and collaboration.",
        "content": "# aectech-hackathon-2024-tag-it"
    },
    {
        "url": "https://github.com/viktor-platform/aectech-spain-1",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Open BID",
        "award": "No Award Found",
        "summary": "A marketplace that clients and designers can upload their projects, and receive back transparent cost bidding from multiple suppliers, specific for that particular building part or contract, and review it within their design model.",
        "content": "# aectech-spain-1\nAECTech 2024 Hackathon Hack 1\n"
    },
    {
        "url": "https://github.com/shapediver/SausageDog_AECTechBarcelona2024",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Sausage Dog",
        "award": "No Award Found",
        "summary": "Simple web tool for running multiobjective optimization on GH models of a hot dog. Ability to dynamically plug-in a complex models to the web solver with segregation of the Design Space from the GA-Solver (cloud based) and integration of an external NSGA-II library into Shapediver AppBuilder.",
        "content": "# SausageDog Hack - AECTech Barcelona 2024\nThis repository contains the results of the SausageDog hack at AECTech Barcelona 2024.\n\n![sausagedog4](https://github.com/shapediver/SausageDog_AECTechBarcelona2024/assets/8183687/aefec7fd-bb33-4aa5-bd37-702f43e62f19)\n\nPresentation: [AECtech_2024_Hotdog_Optimizer.pdf](AECtech_2024_Hotdog_Optimizer.pdf)\n\n## Motivation\n\nWe make complex design spaces accessible to end users without requiring them to operate \nthe various parameters controlling the design space. The end users choose what is important, \nand an optimization algorithm picks options from the design space. \n\n## Technical overview\n\nWe implement a web application that includes an implementation of the \nNSGA-II (Non-dominated Sorting Genetic Algorithm II) algorithm. Please find details about\nthis algorithm and our implementation \n[here](https://github.com/shapediver/AppBuilderSdk/tree/task/optimizer/src/optimization). \n\nThe optimization algorithm runs on the front end, but the population computation\nuses Grasshopper models computed on a ShapeDiver system. This allows us to offload\nthe heavy computations to the cloud and parallelize them. The optimization algorithm\ndoes not require heavy computation and is ideally suited for web browsers. \n\n### Front-end implementation\n\nOur implementation is based on the [ShapeDiver App Builder](https://help.shapediver.com/doc/shapediver-app-builder) \nframework. We extended the React front-end code by the optimizer and a corresponding \nUI widget. You can find our changes in this [pull request](https://github.com/shapediver/AppBuilderSdk/pull/72). \n\nThe optimizer can be used using any Grasshopper model uploaded to ShapeDiver which fulfills\nthe requirements as explained in the following. \n\n### Grasshopper models\n\nDirectory [Grasshopper](Grasshopper) contains example models from which to start. The Grasshopper\nmodels need to include a data output component defining the objectives for the optimization algorithm. \nThey also need to include the App Builder components defining the optimization widget as shown \nin the example models (simply copy those components).\n\nThe optimizer in the front-end is capable of optimizing the following types of parameters of the Grasshopper models: \n\n  * Numbers, Integers\n  * Value lists\n  * Booleans\n\n## How to use it\n\nThe front-end application is deployed [here](https://appbuilder.shapediver.com/v1/main/0.3.0-optimizer/). \nIt can be used using any Grasshopper model uploaded to ShapeDiver that fulfills the requirements explained above. \n\nSome examples: \n\n  * Hot Dog\n    * [Grasshopper model](Grasshopper/HotDog.ghx)\n    * Give it a try [here](https://appbuilder.shapediver.com/v1/main/0.3.0-optimizer/?slug=240421-hotdog)\n  * Barcelona Blocks Optimizer \n    * [Grasshopper model](Grasshopper/BarcelonaBlocksOptimizer.ghx)\n    * Give it a try [here](https://appbuilder.shapediver.com/v1/main/0.3.0-optimizer/?slug=barcelonablocksoptimizer)\n    * ![bcn-gif](https://github.com/shapediver/SausageDog_AECTechBarcelona2024/assets/8183687/530ccdc5-2661-4bb4-b33c-cf2cd785805c)\n\nRead more [here](Hotdog_Optimizer_Readme.pdf).\n\n![hotdog-gif](https://github.com/shapediver/SausageDog_AECTechBarcelona2024/assets/8183687/3e6de337-4bca-4b6d-b5ff-a08f5e1f90bd)\n\n\n"
    },
    {
        "url": "https://github.com/sergiomorph/Geocoris",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Geocoris",
        "award": "No Award Found",
        "summary": "Bi-directional Unity (Meta Quest 3) - Rhino + Grasshopper connection. Provide a real time tool, based on augmented reality, for 3D sketching and previewing scalable parametric models while allowing computational designers to update and modify their real-time streamed Grasshopper definitions.",
        "content": "# Geocoris\n![Geocoris_icon](https://github.com/sergiomorph/Geocoris/assets/84446234/b058d207-f038-433a-9f8e-28f86f842d94)\n\nAECTECH+ Barcelona Hackaton proposal. \nGeocoris is a bi-directional connection between Unity (Meta Quest 3) and Rhino + Grasshopper, using Firebase as a real-time database. \n---------------------------------------------------------------------------\nThe goal is to provide a real time tool for AR Design sketching where computational designer can update and modify theirs streamed Grasshopper definitions.\n\n## Resources\n\n- https://github.com/hodgoong/firehopper\n- https://console.firebase.google.com/project/geocoris-ea2dc/overview\n- https://firebase.google.com/docs/database/rest/start?authuser=0&hl=en\n- https://github.com/bugthesystem/FireSharp\n\n\n"
    },
    {
        "url": "https://github.com/Licini/SmartTutorial",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Smart Tutorial",
        "award": "No Award Found",
        "summary": "A web app to make interactive, 'intelligent' tutorials based on your codebase and domain-specific knowledge. Write a minimal tutorial with general key points, add links to your codebase repo, and let SmartTutorial generate for you a complete and detailed tutorial based on your programming domain.",
        "content": "# SmartTutorial\n\n![](doc/SmartTutorial_2.jpeg)\n\n**SmartTutorial : a web app to make interactive, \u2018intelligent\u2019 tutorials based on your codebase and domain-specific knowledge.**\n\nWrite a minimal tutorial with general key points, add links to your codebase repo, and let SmartTutorial generate for you a complete and detailed tutorial based on your programming domain.\n\n\n### Backend : Python\n\n- Install the required packages from `Pipfile`\n\n`make install-backend` or `pipenv install`\n\n- Add your OpenAI key in an `.openai-key` file in the root folder\n\n- Install embeddings for Compas\n\n`make install-data`\n\n- Run the server\n\n`make run-backend` or `pipenv run backend`\n\n- Serve as daemon\n\n`make start-backend`\n\n`make stop-backend`\n\n### Frontend : Vue\n\n- Install and run the vue app\n\n`make build-frontend` or `cd frontend && npm install`\n\n\n#### Sample\n![example](doc/example.png)\n\n\n#### References\n- [Annoy (Approximate Nearest Neighbors Oh Yeah)](https://github.com/spotify/annoy)\n- [LlamaIndex Github Repo Reader](https://docs.llamaindex.ai/en/stable/examples/data_connectors/GithubRepositoryReaderDemo/)\n- [LlamaIndex Vector Store Index](https://docs.llamaindex.ai/en/stable/understanding/storing/storing/)\n- [private-gpt](https://github.com/zylon-ai/private-gpt?tab=readme-ov-file)\n- [script-gpt](https://wandb.ai/srddev/ScriptGPT/reports/Script-GPT--VmlldzozNjQ4MDA1)\n- [gpt-researcher](https://github.com/assafelovic/gpt-researcher)\n"
    },
    {
        "url": "https://github.com/maxdumas/aectech-hackathon",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "All The Way Down",
        "award": "BEST OVERALL HACK:",
        "summary": "AllTheWayDown allows for managing dependencies within design workflows, which decreases length of time between design iterations, introduces Git-based version control, and eliminates discrepancies between different stages of design. Initially, AllTheWayDown works for Grasshopper script graphs and Rhino models. Future iterations will expand to other design tools and data inputs.",
        "content": "<h1 align=\"center\">\n  <br>\n  AllTheWayDown\n  <br>\n</h1>\n\n![Rhinos ATWD](https://github.com/maxdumas/aectech-hackathon/blob/main/Static/stacked-rhinos-sculpture.png)\n\n<h4 align=\"center\">Dependency management and version control to link every phase of design.</h4>\n\n<p align=\"center\">\n  <a href=\"#why\">Why AllTheWayDown?</a> \u2022\n  <a href=\"#key-features\">Key Features</a> \u2022\n  <a href=\"#how-to-use\">How To Use</a> \u2022\n  <a href=\"#how-to-use\">Next Steps</a> \u2022\n  <a href=\"#credits\">Credits</a> \n</p>\n\n![screenshot](https://github.com/maxdumas/aectech-hackathon/blob/5d2b262d01489dc414fb073afc2a7a84a45a7d01/Static/graph-Growth.gif)\n\n## AllTheWayDown\n\nAllTheWayDown (ATWD) allows for managing dependencies within design workflows, which decreases length of time between design iterations, introduces Git-based version control, and eliminates discrepancies between different stages of design.  Initially, ATWD works for Grasshopper script graphs and Rhino models. Future iterations will expand to other design tools and data inputs.  \n\nATWD was developed at the AEC Tech New York Hackathon 2023 hosted by Thornton Tomasetti CORE studio. The hackathon team included:\n- [Chau Nguyen](https://github.com/minhchau1510) - [Foster + Partners](https://www.fosterandpartners.com)\n- [Keyan Rahimzadeh](https://github.com/keyan-r) - [Grimshaw](https://grimshaw.global)\n- [Max Dumas](https://github.com/maxdumas) - [Ulama](https://ulama.tech)\n- [Nathan Barnes](https://github.com/nathan-barnes) - [Zahner](https://www.azahner.com/)\n- [Patryk Wozniczka](https://github.com/patrykwoz) - [PJW](https://patrykwozniczka.com)\n- [Sarang Pramode](https://github.com/Sarang-Pramode) - [Ulama](https://ulama.tech)\n- [Tyce Herrman](https://github.com/TyceHerrman) - [Ulama](https://ulama.tech)\n\n\n## Key Features\n\n* Dependency Updates \ud83d\udd78\ufe0f\n  - When you make changes to one or more Grasshopper scripts, any script dependencies will be updated upon.\n* Version control \ud83d\udea7\n  - While you type, LivePreview will automatically scroll to the current location you're editing.\n* Dependency Graph Visualization \ud83d\udcc8\n  - See your entire dependency graph and understand how changes are propagated through the graph.\n  ![graph](https://github.com/maxdumas/aectech-hackathon/blob/3d5c470ab543bf1c92de90c93ef8af67afe88dfd/GraphView%20Image.png)\n\n\n## How To Use\n\nTo clone and run this application, you'll need [Git](https://git-scm.com) installed on your computer. You'll also need [Data Version Control](https://dvc.org/doc/install).\n\nFrom your command line:\n\n```bash\n# Clone this repository\n$ git clone https://github.com/maxdumas/aectech-hackathon.git\n\n# Navigate to directory\ncd aectech-hackathon\n\n# Create Mermaid diagram of DVC DAG with:\n$ dvc dag --mermaid > output.mmd\n\n# Navigate to GraphView directory\n\ncd GraphView\n\n# Run mermaid-to-D3-structure.py\npdm run mermaid-to-D3-structure.py\n\n# Start local http server within the GraphView directory (for >Python3)\npython -m http.server 5000\n\n```\n\n\n## Next Steps\n\n* Presently, this tool just works with files with Rhino/Grasshopper integration, but it can eventually work with anything and be design tool agnostic. \n\n* This project could be extended to easily integrate with external APIs as well.\n\n* The project is built on top of Git semantics, so any Git features (branching, commits, etc.) could be abstracted into a  user-friendly experience to bring the power of Git to any designer.\n\n\n## Credits\n\nThis software uses the following open source packages:\n\n- [Data Version Control](https://dvc.org/)\n\nIt also uses\n\n- [Rhinocommon](https://www.rhino3d.com)\n- [Grasshopper](https://www.grasshopper3d.com)\n"
    },
    {
        "url": "https://github.com/rhino-anywhere",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Rhino Anywhere",
        "award": "BEST COLLABORATIVE HACK:",
        "summary": "Rhino Anywhere is a framework that enables high definition streaming of a Rhino Model Viewport to the web. This allows you to reskin and interact with Rhino in any way you desire, whilst still working in the native Rhino Environment. You can create specific command sets for users.",
        "content": null
    },
    {
        "url": "https://github.com/TeamZombies/furne_frontend",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "FURN-E",
        "award": "BEST OPEN SOURCE HACK:",
        "summary": "This Vue.js application uses the OpenAI API to generate images based on a user-provided description and presents the generated images for selection. Additionally, it displays product options based on those generated images.",
        "content": "# Furn-E\nThis Vue.js application uses the OpenAI API to generate images based on a user-provided description and presents the generated images for selection. Additionally, it displays product options based on those generated images. Meant to be used with our [Python backend API](https://github.com/TeamZombies/furne_backend_api).\n\n![](https://github.com/TeamZombies/furne_frontend/blob/main/furne_preview.gif)\n\n## Application Workflow\n\n1. Enter a room description in the provided text field.\n2. Click the \"Go\" button to generate images based on the description.\n3. Select your favorite image by clicking on it to see related product options.\n\n![](https://github.com/TeamZombies/furne_frontend/blob/main/process_diagram.jpg)\n\n## Prerequisites\n\nThis application utilizes\n\n* Vue.js\n* Vuetify\n* Vite\n* An OpenAI API key (credits needed)\n\n## Installation\n1. Clone the repository.\n2. Install dependencies using npm install.\n3. Set up your OpenAI API key by creating a .env file and adding VITE_OPENAI_API_KEY=YOUR_API_KEY.\n\n## Project setup\n\nnpm run dev\n\n"
    },
    {
        "url": "https://github.com/ssajedi/SAiF-GPT",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "SAiF-GPT",
        "award": "No Award Found",
        "summary": "SAiF-GPT aims to provide a solution for using Chat GPT in a secure and compliant manner, even when dealing with sensitive information. To ensure that corporate policies and NDAs are respected, the code and process automate entity detection and anonymization by replacing them with analogous values. The end goal is to allow AEC industry to use AI technology like ChatGPT for document analysis while protecting confidential data.",
        "content": "<img src=\"https://github.com/ssajedi/SAiF-GPT/blob/main/Assets/Logo.png\" width=\"200\">\n\n\n# SAiF-GPT\nProject created for AECTech Hackathon 2023 @ New York.\nSAiF-GPT aims to provide a solution for using Chat GPT in a secure and compliant manner, even when dealing with sensitive information. \nTo ensure that corporate policies and NDAs are respected, the code and process automate entity detection and anonymization by replacing them with analogous values.\nThe end goal is to allow AEC industry to use AI technology like ChatGPT for document analysis while protecting confidential data.\n# Getting Started with SAiF-GPT \nWe are using [Streamlit](https://streamlit.io/) as the front-end of this application. \n1. To get started with SAif-GPT, you should clone the repo onto your local machine and install all requirements using: \n```\npip install -r requirements.txt\n```\nWe recommend setting up a local environment using Anaconda to make sure these pip-installed dependencies don't interfere with your other python projects.\n\n2. Create a \"hack_secret.txt\" file within your local repository and paste your OpenAI API key into that file. This will allow you to call onto an api and actually have your encoded text processed by a large cloud based LLM. \n\n3. Once \"hack_secret.txt\" is saved, you can run the streamlit webapp directly from your terminal using: \n```\nstreamlit run app.py\n```\n4. Streamlit should automatically open an instance of the webapp on your default browser. From there you can upload any PDF in your file browser, and ask questions about it like a traditional chatbot. The caveat, your confidential information will be \"encrypted\"\nContact us if you run into any issues!\n\n![image](https://github.com/ssajedi/SAiF-GPT/assets/132618087/999757ab-6ff6-4d5f-90a1-50bb9f3f57c0)\n## Known Limitations\n- 4096 token limits on ChatGPT-3.5, limits the size of uploaded docs.\n- Missed or misclassified entities are rare but not impossible. \n## Usage/Examples & Future development ideas\n\nThe following features can be integrated into the proposed framework for future development.\n- Retrieval Augmented Generation (RAG) for long pdfs\n- Compatibility with other LLM API's such as ([Claude](https://claude.ai/))\n- Better Named Entity Recognition (NER) models\n- Support for custom user-defined entities\n\n# \u26a0\ufe0f Attention:\nThis project was an outcome of a 24 hour hackathon. Please make sure to test the NER detections on sample of your data before deployment at scale.  \n\n## Presentation\nYou can access the [Presentation pdf here.](https://github.com/ssajedi/SAiF-GPT/blob/main/Assets/Spec%20LLM.pdf)\n\n## Team\n- [Agustina Aboy](https://github.com/agusaboy)\n- [Alexis Kotzambasis](https://github.com/lexiko80-LPA) \n- [Aman Sharma](https://github.com/aspeculat0r)\n- [Carlos Luiz Amaral](https://www.github.com/closa1211)\n- [Dan Miller](https://www.github.com/djmillerDeg)\n- Kodai Endo / ek819@outlook.com\n- [Omid Sajedi](https://github.com/ssajedi)\n- Rintaro Yamashita / intaro0626@gmail.com\n- [Samuel Winson Tanuwidjaja](https://www.github.com/samuelwt)\n- [Sierra Davis](https://www.github.com/sierra-md)\n\nProof we were [here](https://github.com/ssajedi/SAiF-GPT/tree/main/Assets/photos)\n## Acknowledgements\n\u2728 Special thanks to: \n- Tamaho for helping with team communication with translations.\n- Alexander Matthias Jacobson for his initial insight on brainstorming and being the brave one to jump out of the boat.\n## License\n[MIT](https://github.com/ssajedi/AInonymous/blob/main/LICENSE)\n"
    },
    {
        "url": "https://github.com/SHL-Digital-Practice/the-boring-labels",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Boring",
        "award": "No Award Found",
        "summary": "Smart Real-time Naming for Your Spaces",
        "content": null
    },
    {
        "url": "https://github.com/czwangxtt/AEC-Hack",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "AECademy",
        "award": "No Award Found",
        "summary": "A Sketch-Based Content Retrieval System, an innovative search engine that allows users to use sketches to search for relevant content within a digital database. It is designed to interpret the attributes of the sketched input and provide results such as PDF documents, 3D models, and detailed text descriptions that closely match the sketch.",
        "content": "# Sketch-Based Content Retrieval System\n\n## Overview\n\nThis repository contains the code for a Sketch-Based Content Retrieval System, an innovative search engine that allows users to use sketches to search for relevant content within a digital database. It is designed to interpret the attributes of the sketched input and provide results such as PDF documents, 3D models, and detailed text descriptions that closely match the sketch.\n\n## Features\n\n- **Sketch Recognition**: Implementing advanced algorithms to analyze the sketch and extract searchable attributes.\n- **Content Matching**: Sophisticated search functionality that finds and ranks content based on its relevance to the sketched attributes.\n- **Multi-Format Support**: Compatibility with a variety of content formats, including PDFs, 3D model files, and text documents.\n- **User-Friendly Interface**: A simple and intuitive interface that makes it easy for users to upload sketches and view results.\n- **Scalable Database**: A robust and scalable database that can handle a large number of entries and a variety of content types.\n\n## Installation\n\nTo set up the Sketch-Based Content Retrieval System on your local machine, follow these steps:\n\n```bash\ngit clone https://github.com/your-username/sketch-based-retrieval.git\ncd sketch-based-retrieval\n# Set up your virtual environment\npython -m venv venv\n# Activate the virtual environment\n# On Windows\nvenv\\Scripts\\activate\n# On Unix or MacOS\nsource venv/bin/activate\n# Install required dependencies\npip install -r requirements.txt\n"
    },
    {
        "url": "https://github.com/PickardChilton/XRVZ/tree/main",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "XRVZ",
        "award": "No Award Found",
        "summary": "Open source WebXR viewer that works on any WebXR-enabled device running in an immersive model viewer, plugging into analysis models like Forma, Hypar, or Viktor for heightened understanding of data",
        "content": "# XRVZ\n\nXRVZ was initially developed at the 2023 AEC Tech Hackaton, held on Nov 4-5 at Thornton Thomasetti's offices in New York. It is a collaboration between Flad Architects, NBBJ, Pickard Chilton, Turner Construction, and the Autodesk Forma team. View the web app at https://pickardchilton.github.io/XRVZ\n"
    },
    {
        "url": "https://github.com/snabela/AECTech2023 ",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "COLLAB",
        "award": "No Award Found",
        "summary": "This hackathon leverages a diverse range of tools to create a interactive structural optimization and review web applet built in Viktor.",
        "content": "<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->\n<a name=\"readme-top\"></a>\n\n<!-- PROJECT SHIELDS -->\n<!--\n*** I'm using markdown \"reference style\" links for readability.\n*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).\n*** See the bottom of this document for the declaration of the reference variables\n*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.\n*** https://www.markdownguide.org/basic-syntax/#reference-style-links\n-->\n[![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n\n\n\n<!-- PROJECT LOGO -->\n<br />\n<div align=\"center\">\n  <a href=\"https://github.com/othneildrew/Best-README-Template\">\n    <img src=\"assets/logo.png\" alt=\"Logo\" width=\"800\" height=\"400\">\n  </a>\n\n  <h3 align=\"center\">Best-README-Template</h3>\n\n  <p align=\"center\">\n    An awesome README template to jumpstart your projects!\n    <br />\n    <a href=\"https://github.com/othneildrew/Best-README-Template\"><strong>Explore the docs \u00bb</strong></a>\n    <br />\n    <br />\n    <a href=\"https://github.com/othneildrew/Best-README-Template\">View Demo</a>\n    \u00b7\n    <a href=\"https://github.com/othneildrew/Best-README-Template/issues\">Report Bug</a>\n    \u00b7\n    <a href=\"https://github.com/othneildrew/Best-README-Template/issues\">Request Feature</a>\n  </p>\n</div>\n\n\n\n<!-- TABLE OF CONTENTS -->\n<details>\n  <summary>Table of Contents</summary>\n  <ol>\n    <li>\n      <a href=\"#about-the-project\">About The Project</a>\n      <ul>\n        <li><a href=\"#built-with\">Built With</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"#getting-started\">Getting Started</a>\n      <ul>\n        <li><a href=\"#prerequisites\">Prerequisites</a></li>\n        <li><a href=\"#installation\">Installation</a></li>\n      </ul>\n    </li>\n    <li><a href=\"#usage\">Usage</a></li>\n    <li><a href=\"#roadmap\">Roadmap</a></li>\n    <li><a href=\"#contributing\">Contributing</a></li>\n    <li><a href=\"#contact\">Contact</a></li>\n    <li><a href=\"#acknowledgments\">Acknowledgments</a></li>\n  </ol>\n</details>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\nThis hackathon leverages a diverse range of tools to create a interactive structural optimization and review web applet built in Viktor. \n\nKey technologies leveraged incule Shapediver, Cesium, Etabs API, Grasshopper, Google Earth 3d Tiles, and custom Python analysis to generate parametric structural systems, review the design options in rich 3d context, and optimize construction systems, while also validating structural, sismic, and wind load concerns. \n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n### Built With\n\n* Viktor\n* Shapediver\n* Python\n* ETABS API\n* Google Tiles\n* Cesium\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\n\n### Prerequisites\nYou will need viktor installed along with installing a viktor generic worker. The viktor generic worker can be installed on any remote machine that has access to ETABS.\n\nPlease see the commented files in the viktor folder for more information.\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n\n<!-- USAGE EXAMPLES -->\n## Usage\n\nSee our live demo!\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n\n<!-- ROADMAP -->\n## Roadmap\n\n- [x] Add Changelog\n- [x] Add back to top links\n- [ ] Add Additional Templates w/ Examples\n\nSee the [open issues](https://github.com/othneildrew/Best-README-Template/issues) for a full list of proposed features (and known issues).\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n\n<!-- CONTRIBUTING -->\n## Contributing\n\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.\n\nIf you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\".\nDon't forget to give the project a star! Thanks again!\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n<!-- TEAM -->\n## Team\n* Alexander Schiftner\n* Brian Stuchel\n* Moustafa El-Sawy\n* Georgios Athanasopoulos\n* Nicolas Azel\n* Murat Melek\n* Stijn Jansen\n* Wendy C\n* Yang Xie\n* Victor Calderon\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n\n<!-- ACKNOWLEDGMENTS -->\n## Acknowledgments\n\nThanks to AEC Tech 2023 for holding such a great event and for all participants for sharing their knowledge and experience. Special thanks to Viktor and Shapediver for allowing us to use and utilize their powerful platforms.\n\nwww.viktor.ai\n\nwww.shapediver.com\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n[contributors-shield]: https://img.shields.io/github/contributors/othneildrew/Best-README-Template.svg?style=for-the-badge\n[contributors-url]: https://github.com/othneildrew/Best-README-Template/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/othneildrew/Best-README-Template.svg?style=for-the-badge\n[forks-url]: https://github.com/othneildrew/Best-README-Template/network/members\n[stars-shield]: https://img.shields.io/github/stars/othneildrew/Best-README-Template.svg?style=for-the-badge\n[stars-url]: https://github.com/othneildrew/Best-README-Template/stargazers\n[issues-shield]: https://img.shields.io/github/issues/othneildrew/Best-README-Template.svg?style=for-the-badge\n[issues-url]: https://github.com/othneildrew/Best-README-Template/issues\n[license-shield]: https://img.shields.io/github/license/othneildrew/Best-README-Template.svg?style=for-the-badge\n[license-url]: https://github.com/othneildrew/Best-README-Template/blob/master/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n[linkedin-url]: https://linkedin.com/in/othneildrew\n[product-screenshot]: images/screenshot.png\n[Next.js]: https://img.shields.io/badge/next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white\n[Next-url]: https://nextjs.org/\n[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB\n[React-url]: https://reactjs.org/\n[Vue.js]: https://img.shields.io/badge/Vue.js-35495E?style=for-the-badge&logo=vuedotjs&logoColor=4FC08D\n[Vue-url]: https://vuejs.org/\n[Angular.io]: https://img.shields.io/badge/Angular-DD0031?style=for-the-badge&logo=angular&logoColor=white\n[Angular-url]: https://angular.io/\n[Svelte.dev]: https://img.shields.io/badge/Svelte-4A4A55?style=for-the-badge&logo=svelte&logoColor=FF3E00\n[Svelte-url]: https://svelte.dev/\n[Laravel.com]: https://img.shields.io/badge/Laravel-FF2D20?style=for-the-badge&logo=laravel&logoColor=white\n[Laravel-url]: https://laravel.com\n[Bootstrap.com]: https://img.shields.io/badge/Bootstrap-563D7C?style=for-the-badge&logo=bootstrap&logoColor=white\n[Bootstrap-url]: https://getbootstrap.com\n[JQuery.com]: https://img.shields.io/badge/jQuery-0769AD?style=for-the-badge&logo=jquery&logoColor=white\n[JQuery-url]: https://jquery.com \n"
    },
    {
        "url": "https://github.com/EZ-Script/EZRX-Scripting",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Ez.Rx",
        "award": "No Award Found",
        "summary": "EZRX is a plug-in for Rhino that helps a user use Chat GPT to create scripted Grasshopper nodes.",
        "content": "# EZRX-Scripting\n\n<img width=\"815\" alt=\"image\" src=\"https://github.com/EZ-Script/EZRX-Scripting/assets/1759994/062a3cd0-ca14-40ba-9502-911c6ef1e2b5\">\n\n# Overview\n\nEZRX is a plug-in for Rhino that helps a user use Chat GPT to create scripted Grasshopper nodes. We built this for the AEC Tech 2023 Hackathon in New York hosted by CORE studio and Thornton Thomasetti.\n\n<img width=\"789\" alt=\"image\" src=\"https://github.com/EZ-Script/EZRX-Scripting/assets/1759994/08191c6e-8b9b-463a-8190-72236105c94e\">\n\n# Background and Motivation\n\nArchitects don't have time or motivation to learn to code, but would benefit from using scripts for creating reproducible workflows and more complex forms. \n\n<img width=\"858\" alt=\"image\" src=\"https://github.com/EZ-Script/EZRX-Scripting/assets/1759994/85be4260-c55f-4816-ae4f-1ae264c18620\">\n\nToday an architect can use Chat GPT to request code, but someone without programming experience can find it hard to get Chat GPT to produce working code. \nThey need to provide sufficient context with the prompt to get a working result. \n\n# What we did \n\nA lot of our time was spent as a group trying to understand narrow down our original mandate of \"making coding easier\". We wanted to understand what that \nmeant exactly, how we might achieve that, which persona we wanted to focus on and what use case we were targetting. \n\nOnce we arrived at the we designed and coded three primary components:\n\n* A tool for generating grasshopper nodes that dynamically compile and execute arbitrary C# code read from a file\n* An API for sending prompts to and reading responses of the Chat GPT API, with additional context provided to prompt to produce better code\n* A UI to allow the user to provide a prompt and review the generated code, before generating a node from it\n\n# Architecture Overview\n\n<img width=\"827\" alt=\"image\" src=\"https://github.com/EZ-Script/EZRX-Scripting/assets/1759994/900ab1a6-3ab6-4904-9aee-156b32345a06\">\n\n# Libraries used\n\n* Rhino API - For creating Grasshopper nodes \n* Roslyn SDK - C# Compiler\n* [Ara3D Library](https://github.com/ara3d/ara3d) - utility library and convenience functions\n* [OpenAI Unoffical .NET API](https://github.com/OkGoDoIt/OpenAI-API-dotnet) \n\n# Cloning the Repository \n\nThis module used the `github.com\\ara3d\\ara3d` project as a submodule.\n\nFrom the command-line you can pull the submodules using:\n\n```\ngit submodule update --init --recursive\n```\n\n# Building and Running the Code\n\nWe only had time to get the code running on one user's machine and \nunfortunately do not have the steps documented to run the system.   \n\n# What we learned \n\n* Don't post API keys to Github\n* If you accidentally post your OpenAPI API key to Github, OpenAPI will revoke it very quickly!\n* Don't ask too much from your prompt or it can get confused \n* Chat GPT 4 is much more powerful than GPT 3.5 and can handle more complex requests \n* Getting working code requires providing a lot of additional context  \n* We found that the unofficial OpenAPI .NET worked better than the official one.\n* How you phrase a prompt makes a big difference\n* ChatGPT will not always produce the same results.\n* Architects don't necessarily want to learn to code, they want to realize their designs quicker \n  \n# Next Steps \n\nWe only had 26 hours to write the code and submit the presentation so there is a lot left to do. \n\n## Technical Debt and Code Clean-up \n* Test the system on other person's machine \n* Refactor the code to make it easier to run and modify\n* Create an installer\n* Document the build process\n\n## Features \n\n* Storing prompts and the results and making them searchable\n* Supporting different output types other than just mesh \n* Allowing customized inputs\n* Allow the prompt contexts to be updated by the user\n* Allow the generated code to be used in other context\n* Train models to create and recognize a generic structure for describing inputs/outputs \n\n\n\n# Who are We\n\nWe are the EZ Script team. \n* Christopher Diggins - Software Developer\n* Emma Xu - Architecture Student\n* Travis Potter - Software Engineer and MEP Engineer\n* Haki Sallaku - Computer Science Student\n* Sun Lee - Computational Designer and Architect\n* Bell Wang - Architecture Student\n* Marcelo Villalba - Software Engineer\n\n![ezrx-img_3665](https://github.com/EZ-Script/EZRX-Scripting/assets/1759994/8a5a9ae2-b759-4b8d-a2f2-2dbbda13120b)\n\n<img width=\"183\" alt=\"image\" src=\"https://github.com/EZ-Script/EZRX-Scripting/assets/1759994/6b446619-c935-4029-b7f8-42e4312101c0\">\n\n"
    },
    {
        "url": "https://github.com/jackDang2803/FindIt",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "FindIT",
        "award": "No Award Found",
        "summary": "Forestry Identification and Navigation forDigital Imaging Transfer",
        "content": "# FindIt!\r\n\r\n_It was developed at the AEC Tech New York Hackathon 2023 hosted by Thornton Tomasetti CORE studio_\r\n\r\nStarting from 2D graphs to 3D meshes representing trees.\r\nTwo approaches:\r\n\r\n* Using ML algorithms (openCV) to detect patterns on a image and return the center point of each tree.\r\n\r\n* Send the image to our API running Meta AI Segment Anything Model(SAM)\r\n\r\nBoth procedures result in very capable tree detection (80% accuracy).\r\n\r\n\r\n*It can also run using sketches!*\r\n\r\n![Segmentation](docs/input.png)\r\n\r\n*And this is how it looks*\r\n![Result](docs/result.png)\r\n\r\n# Team\r\n* Pablo Derendinger - e-Verse\r\n* Pawel Sapiecha - Olson Kundig\r\n* Quoc Dang - KPF\r\n* Hailey Kim - ARUP\r\n* Shariful Anik - Mithun\r\n\r\n# How to\r\n### ML Approach\r\n1. Install [GH Python remote](https://github.com/pilcru/ghpythonremote)\r\n1. Open the GH script\r\n1. Import an satellite image and the template image (snip of the tree you want to detect)\r\n\r\n1. Run the script and new trees will placed on Rhino\r\n\r\n### AI Approach\r\n\r\n1. Clone this repository \r\n1. Run ```pip -r requirements.txt```\r\n1. Run the SAM model from the sample inside the main.py file. Remember to store the image you want to detect to the same folder under the name ```input.png```\r\n1. The script will export a CSV file with name.\r\n1. Use the csv as in put for the Grasshopper file\r\n\r\n\r\n\r\n\r\n# License\r\n\r\nThe MIT License (MIT)\r\nCopyright \u00a9 2023 \r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n"
    },
    {
        "url": "https://github.com/phzx3691/WasteD-Image-Labeling",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Wasted",
        "award": "No Award Found",
        "summary": "Unlock value in existing end of service buildings. Use Reality Capture, AI and Parametric Design to define value, repurpose, and reuse.",
        "content": "# WasteD-Image-Labeling\n \n### Use Reality Capture, AI and Parametric Design to define value, repurpose, and reuse.\n\n#### Slideshow\n[Google Sheets](https://docs.google.com/presentation/d/1c3wDrxQE_8WFN_ddVDlxcGXIzNFhnwPl4-7m_3E6GQY/edit#slide=id.gfc1e3d8d1b_3_63)\n\n#### Github Projects\n\n[Image Material Classification](https://github.com/phzx3691/WasteD-Image-Labeling)  \n[Interactive Dashboard](https://github.com/jbf1212/aectech23-streamlit-reuse)  \n[Unity Visualization/Validation mobile app](https://github.com/timera/Wasted-PointCloudInterface/)  \n[Structural SAP Analysis](https://github.com/phzx3691/Wasted-Structural-SAP-Analysis)  \n"
    },
    {
        "url": "https://github.com/RolandoV/RAMit",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "RAMit",
        "award": "No Award Found",
        "summary": "Revit to Ram Concept Interoperability",
        "content": null
    },
    {
        "url": "https://github.com/enmerk4r/GHPT",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "GhPT",
        "award": "BEST OVERALL HACK:",
        "summary": "This project sets out to find a way to leverage the power of ChatGPT to create Grasshopper definitions.",
        "content": "# GHPT\nThis project sets out to find a way to leverage the power of ChatGPT to create Grasshopper definitions.\nIt was developed at the AEC Tech Seattle Hackathon 2023 hosted by Thornton Tomasetti CORE studio and LMN\n\n![0 1 4_README](https://github.com/enmerk4r/GHPT/assets/9583495/91b22bdd-ac9f-4f0e-8a1a-727ddb44ff53)\n\n## Team\n- [Callum Sykes](https://github.com/clicketyclackety) - StructureCraft\n- [Jo Kamm](https://github.com/jkamm) - Dimensional Innovations\n- [Sergey Pigach](https://github.com/enmerk4r) - Thornton Tomasetti\n- [Ryan Erbert](https://github.com/RyanErbert)\n- [Quoc Dang](https://github.com/jackDang2803)\n\n## Installation\nYour options for installing GHPT are as follows:\n- Install the plug-in from [Food4Rhino](https://www.food4rhino.com/en/app/ghpt).\n- Install the GHPT Yak package from Rhino's Package Manager.\n- Build from source.\n\n## Token Configuration\nOnce GhPT is downloaded and installed, the OpenAI token key needs to be set up through the pop-up Token Configuration Window. To use the OpenAI API, you need to provide an API key and specify a GPT model.\n![0 1 4_README_API](https://github.com/enmerk4r/GHPT/assets/9583495/117d2ee2-82f8-44a8-bc57-26baa23fc1c3)\n\n\nYou can sign up for OpenAI API on [this page](https://openai.com/product). Once you signed up and logged in, open [this page](https://platform.openai.com/account/api-keys) and select Create new secret key. You can then copy the key by clicking on the green text Copy, make sure to save this key somewhere else as you will not be able to access it again.\n![image](https://github.com/enmerk4r/GHPT/assets/114206649/66441be3-3c87-4de1-81ca-71a1565347ce)\n\nSelect your model from the dropdown menu\n\n![image](https://github.com/enmerk4r/GHPT/assets/9583495/6c01db32-d336-4848-aa67-3fa7a2129b2c)\n\nPaste the key in the GPT Token box.\n\n![image](https://github.com/enmerk4r/GHPT/assets/9583495/96648b0a-3cdb-4662-8b8f-d92c97a8b417)\n\n\nGo to [this page](https://platform.openai.com/account/rate-limits) to check for your access to different GPT models (currently we are using the more advanced model GPT-4 that has limited access) but model GPT-3.5 should also work well.\n![gpt model](https://github.com/enmerk4r/GHPT/assets/114206649/fd61e092-9a65-484b-b394-93e22a1263cf)\n\n\n\n## How to use\n\nCreating a component and initiating a request to the ChatGPT API can be accomplished via shortcut; Prompts can be written directly into the grasshopper component search function.\n\n![image](https://github.com/enmerk4r/GHPT/assets/9583495/4cb263b5-6a15-4f1d-98cf-4d6e65c93977)\n\nTo take advantage of this functionality, double click an empty space on the canvas and type a prompt in the following format:\n\n`GHPT = <your prompt goes here>`\n\nAfter allowing the module some time to think, an organized node graph will appear. Additionally, an \"Advice\" text panel will be create to display advice/feedback from GPT.\n\nIn the event that a prompt is too complex, the module will display an error message.\n\n\nPrompt guide - add these text snippet at the end of your request for more specific instructions to GPT\n\n* \"if there are questions, put them in the Advice section\" -> if your prompt is too complex for GPT, this allow GPT to ask for clarification\n* \"prefer Circle over Circle CNR\" -> instruct GPT to prefer a component over another one with similar name/function\n* \"be specific\" -> more clarified\n"
    },
    {
        "url": "https://github.com/chinsishe/carbonhacker",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Carbon Hacker",
        "award": "BEST COLLABORATIVE HACK:",
        "summary": "No Summary Found",
        "content": "# Carbon Hacker: Operational Carbon Calculator\n\nCarbon Hacker is a web tool for home/building owners and designers to understand the current and future operational carbon\nemissions of their existing or proposed buildings due to their grid electricity and on-site fossil fuel usage, as well as the\nimpact of PV on the net emissions.\n\nThe only inputs required are a zip code, building type, building area, and annual electricity/gas consumption, the last of\nwhich home/building owners can get from their utility bills.\nThe tool shows both the conventional average carbon emissions as well as [marginal emissions](https://lmnarchitects.com/lmn-research/13-operational-carbon-design-process),\nthe latter of which is an important metric for building designers.\n\nThis tool goes beyond other operational carbon emission calculators by providing a simple interface for homeowners, providing\nemissions from now through the next 30 years as the electricity grid changes, including marginal emissions in addition to\naverage emissions for designers, and using a more accurate hourly energy and grid emission analysis that captures\nimportant time-based correlations between the grid generation mix (e.g. clean PV vs. dirty natural gas plants) and the\nbuilding energy consumption.\n\n![](Assets/CarbonHacker_Screenshot.png)\n\nThis project was part of the [2023 AECtech Hackathon in Seattle](https://www.aectech.us/seattle-hackathon).  It is open-source\nand relies entirely on other open-source tools and datasets.\n\n### Team Members\n- Sishe Jeff Chin\n- Margarita Ganeva\n- Heinrich Hoza\n- Daniel Mayall\n- Pawel Sapiecha\n- Chris Savage\n- Fendy Setiawan\n- Chuou Zhang\n\n## Screenshot\n\n![Screenshot](Assets/CarbonHacker_Screenshot.png)\n\n\n## Framework\n\nThe tool contains a python backend and javascript frontend.  From the user's zip code and building typology (e.g. single-family\nresidential), the backend locates the nearest reference building data from a database containing precalculated electricity and\ngrid carbon emissions for a variety of building typologies and locations across the U.S. The frontend post-processes the reference\ndata to scale it to the user's provided building area and energy usage, then provides an interactive visualization using the\nopen-source [D3.js](https://d3js.org/) and [Leaflet](https://leafletjs.com/) libraries. \n\n![](Assets/Workflow_Screenshot.png)\n\nThe database is generated using the state-of-the-art open-source [EnergyPlus energy modeling software](https://energyplus.net/),\npublicly-available [DOE/PNNL prototype building models](https://www.energycodes.gov/prototype-building-models),\npublicly-available [OneBuilding.org weather files](https://climate.onebuilding.org/),\nand the publicaly-available [NREL Cambium grid carbon emissions data](https://scenarioviewer.nrel.gov/)\n(Cambium provides localized, hourly grid carbon emissions from now through 2050).\nThe [pvlib python library](https://pvpmc.sandia.gov/applications/pv_lib-toolbox/) can be used to generate hourly PV data,\nbut incorporation of this tool was not complete as of completion of the Hackathon.\nThe energy modeling, grid emissions, and PV data are all done on a local, weather-based, hourly basis and thus captures\nimportant time-based correlations between the grid generation mix (e.g. clean PV vs. dirty natural gas plants) and the\nbuilding energy consumption.\n\nThe repo contains python scripts to build the reference building database by running the appropriate prototype building\nenergy models at each available weather station, then combining hourly energy data with corresponding hourly grid emissions\ndata.\n\n\n## Usage\n\n**TBD.**\n"
    },
    {
        "url": "https://github.com/kcpgilbert/HeatIslandHero",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Heat Island Hero",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": "![image](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/20c6ff61-b377-458c-bb22-fd3fdb1826a8)\n\n# HeatIslandHero\n\nHeatIslandHero is a website that allows users to search for urban heat island impact and sensitivity data accross census tracts in Los Angeles County. This data will be displayed both on a map and in list format to the user. HeatIslandHero also searches the relevant census tracts for buildings that are good candidates for the addition of green roofs in the area and displays these to the users. \n\n## Collaborators\n\nThis project was created at the AECtech Hackathon 2023 in Los Angeles by the following collaborators. \n![image](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/36d63d0d-efc9-4133-8212-3c82ab302d07)\n\n## System Demo\n\nBelow is an image showing the initial user interface, and an image showing the interface once the user has run a query.\n![Screenshot 2023-05-21 at 11 13 35 AM](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/20ef7971-5fb0-434f-bd3c-a88c08fa179e)\n![Screenshot 2023-05-21 at 11 13 00 AM](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/de84fc7e-8c5d-49a3-85e5-f2f64fe0025a)\n\nThe system demo video can be downloaded using the following link: https://drive.google.com/file/d/11aIrgMOXyhkYbTGYW17ciapS4pWGL46F/view\n\n## System Overview\n![image](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/c7bac068-b0f9-46e5-a049-4f27b517247e)\n![image](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/b2bab462-227e-4786-bea6-1381e0a24ed8)\n![image](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/4ce3149d-6b1b-4d61-902a-01ca3eb5dfb4)\n![image](https://github.com/kcpgilbert/HeatIslandHero/assets/120534381/5bf0afae-fc05-4ee6-b313-02d0eaa951eb)\n\n## Setup\n\n1. Create a file named `secrets.json` inside of the `server` directory. The contents of the file should be as follows:\n```\n{\n    \"gpt-token\" : \"<YOUR-OPEN-AI-TOKEN-HERE>\"\n}\n```\n2. In the root directory run `pip install -r requirements.txt`\n3. To run the backend server `cd server`, then execute `flask run`\n\n## Data Sources\nCheck out our data folder for the downloadable csv, and geojson data, as well as the merged dataset that was used to create the SQL database.\n- UHI, health index and census data for LA county https://cal-heat.org/download\n- Open Streets Map https://www.openstreetmap.org/#map=5/38.007/-95.844\n- UHI Indec raster map https://www.arcgis.com/home/item.html?id=1b6cad6dd5854d2aa3d215a39a4d372d\n"
    },
    {
        "url": "https://github.com/mirahx24/AECTech-Hackathon-ClimateCanvas",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "C-Canvas",
        "award": "BEST COLLABORATIVE HACK:",
        "summary": "No Summary Found",
        "content": "# Climate Canvas: Interactive Art Exhibit\n\nClimate Canvas is an interactive art exhibit that challenges designers to rethink their design decisions in light of the future climate. By incorporating climate data from Los Angeles (LA) for both current and projected future conditions, the exhibit aims to raise awareness about the potential impact of design choices on our environment.\n![ezgif com-video-to-gif](https://github.com/mirahx24/AECTech-Hackathon-ClimateCanvas/assets/14883017/58f778aa-797a-44fc-aff6-ebecb7dbddaa)\n\n\n## Collaborators\n\nThis project was made possible by the collaborative efforts of talented individuals who brought their unique skills and expertise:\n\n![C-CANVAS_Team](https://github.com/mirahx24/AECTech-Hackathon-ClimateCanvas/assets/14883017/7655a8f7-ce77-40c3-b5d4-8eb506cae52b)\n\n## Features\n\n- Engaging and immersive art installation.\n- Integration of climate data to generate visual representations.\n- Interactive experience through audience participation.\n- Voice prompts and questions to engage the audience.\n- Dynamic art transformations based on the audience's responses.\n\n## Workflow\n![C-CANVAS_WORKFLOW Page 007](https://github.com/mirahx24/AECTech-Hackathon-ClimateCanvas/assets/14883017/4f860080-2298-4e9c-855c-3d69b602027f)\n\n## Image Processing\n![C-CANVAS_WORKFLOW Page 009](https://github.com/mirahx24/AECTech-Hackathon-ClimateCanvas/assets/14883017/4772a27c-4ff1-4f05-93aa-0dc4143262c0)\n\n## Technologies Used\n\n- HTML, CSS, JavaScript for the frontend development.\n- p5.js library for generating interactive visuals.\n- ml5.js library for machine learning for web applicatio.\n- PoseNet library for guesture detection.\n- Processing for Generative Art using climate data for LA.\n- Voice recording and playback for delivering prompts and questions.\n- Web-based camera detection for measuring audience responses (hand raising).\n\n## Installation\n\n1. Clone the repository: `git clone https://github.com/mirahx24/AECTech-Hackathon-ClimateCanvas`\n2. Open the project folder: `cd AECTech-Hackathon-ClimateCanvas`\n3. Launch the exhibit by opening `home.html` in a web browser.\n\n## Usage\n\n1. Upon launching the exhibit, the audience will be greeted with an immersive art installation representing the current climate conditions in LA.\n3. The audience can respond by raising their hands, which will be detected using the webcam.\n4. Based on the audience's response, the art will dynamically transform to reflect different scenarios and potential outcomes.\n5. The exhibit will provide a visual representation of the future climate in LA and stimulate conversations about sustainable design practices.\n\n## Future Enhancements\n\n- Adding voice clip for question prompting.\n- Incorporate real-time climate data to provide up-to-date visualizations.\n- Expand the exhibit to include multiple locations and climate scenarios.\n- Introduce additional interactive elements to engage the audience further.\n- Implement machine learning algorithms to analyze audience responses and generate personalized art experiences.\n- Create a data visualization dashboard to display historical and projected climate data.\n\n\n## Acknowledgements\n\n- p5.js: [p5.js](https://p5js.org/)\n- ml5.js: https://ml5js.org/\n- PoseNet: https://github.com/tensorflow/tfjs-models/tree/master/posenet\n- Processing: https://processing.org/\n- EPA EJScreen: https://ejscreen.epa.gov/mapper/\n"
    },
    {
        "url": "https://github.com/sophXmoore1/snapCycle",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Snap Cycle",
        "award": "MOST SUSTAINABLE HACK:",
        "summary": "No Summary Found",
        "content": "# snapcycle\n\n## Project setup\n```\nnpm install\n```\n\n### Compiles and hot-reloads for development\n```\nnpm run serve\n```\n\n### Compiles and minifies for production\n```\nnpm run build\n```\n\n### Lints and fixes files\n```\nnpm run lint\n```\n\n### Customize configuration\nSee [Configuration Reference](https://cli.vuejs.org/config/).\n"
    },
    {
        "url": "https://github.com/AntonioWritesCode/CarbonEater",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Sustainable Collaborators",
        "award": "No Award Found",
        "summary": "Read structural template image and optimize carbon output.",
        "content": null
    },
    {
        "url": "https://github.com/clicketyclackety/Crash",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Crash!",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": "# This repo has been archived. Crash's active development can be found at [Crash Cloud](https://github.com/crashcloud/crash)\n\n\n<a name=\"readme-top\"></a>\n\n<!-- PROJECT SHIELDS -->\n[![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n[![MIT License][license-shield]][license-url]\n\n<!-- PROJECT LOGO -->\n<div align=\"center\">\n  <a href=\"https://github.com/clicketyclackety/Crash\">\n    <img src=\"Logo.png\" alt=\"Logo\" width=\"400\" height=\"300\">\n  </a>\n\n  <p align=\"center\">\n    A multi-user collaborative environment for Rhino\n    <br />\n    <a href=\"https://rhinocrash.notion.site/CRASH-6fdc9286ff33490487c6585b2f17c33d\">User Guide</A>\n    \u00b7\n    <a href=\"https://github.com/clicketyclackety/Crash/issues\">Report Bug</a>\n    \u00b7\n    <a href=\"https://github.com/clicketyclackety/Crash/issues\">Request Feature</a>\n  </p>\n</div>\n\n<!-- TABLE OF CONTENTS -->\n<details>\n  <summary>Table of Contents</summary>\n  <ol>\n    <li>\n      <a href=\"#about-the-project\">About The Project</a>\n    </li>\n    <li>\n      <a href=\"#baby-poweruser-getting-started\">Poweruser Getting Started</a>\n    </li>\n    <li>\n      <a href=\"#man_technologist-woman_technologist-developer-getting-started\">Developer Getting Started</a>\n    </li>\n    <li><a href=\"#workflow-overview\">Workflow Overview</a></li>\n    <li><a href=\"#roadmap\">Roadmap</a></li>\n    <li><a href=\"#contributing\">Contributing</a></li>\n    <li><a href=\"#license\">License</a></li>\n    <li><a href=\"#acknowledgments\">Acknowledgments</a></li>\n  </ol>\n</details>\n\n<!-- ABOUT THE PROJECT -->\n## About The Project\nThis project has been completed as part of the TT AEC Hackathon 2022 - New York. This plugin/application allows users to collaborate on a single central Rhino model. The Team Members for this awesome project are (in alphabetical order):\n* [Callum Sykes](https://www.linkedin.com/in/callumsykes/)\n* [Curtis Wensley](https://www.linkedin.com/in/cwensley/)\n* [Erika Santos](https://www.linkedin.com/in/erikasantosr/)\n* [Lukas Fuhrimann](https://www.linkedin.com/in/lfuhrimann/)\n* [Morteza Karimi](https://github.com/karimi)\n* [Moustafa El-Sawy](https://www.linkedin.com/in/moustafakelsawy/)\n* [Russell Feathers](https://www.linkedin.com/in/russell-feathers/)\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n### Built With\n* [Visual Studio 2022](https://visualstudio.microsoft.com/vs/)\n* [SignalR](https://learn.microsoft.com/en-us/aspnet/signalr/overview/getting-started/introduction-to-signalr)\n* [SQLite](https://www.sqlite.org/index.html)\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- POWERUSER GETTING STARTED -->\n## :baby: Poweruser Getting Started\nThanks for checking out CRASH! Please follow the steps below to get started in no time! Please make sure you have all the <a href=\"#prerequisites\">Prerequisites</a> to have a smooth and fun experience!\n\n### Prerequisites\nYou will need the following libraries and/or software installed before getting to the fun!\n* [Rhino 7.21+](https://www.rhino3d.com/download/)\n\n### Installing CRASH from YAK\n1. Launch Rhino 7\n2. Type in PackageManager or go to Tools --> Package Manager\n3. Search for Crash and press Install.\n4. Close and Re-launch Rhino 7.\n\n### Using Crash\nTo host a new shared model:\n1. Type `StartSharedModel` command in Rhino.\n2. Enter your name when prompted.\n3. Specify an open port on your machine to run the server\n4. Others can join the session using url `<your_ip_address>:<port>`\n\n![Alt Text](https://media.giphy.com/media/oNuY0wsiDV5XFmYuNw/giphy.gif)\n\nTo Join a shared model:\n1. Type `OpenSharedModel` command in Rhino.\n2. Enter your name when prompted.\n3. Enter the server URL from step 4 above.\n\nYou're now connected in a collaborative session. To commit your changes to the central model use the `Release` command.\n\n<!-- DEVELOPER GETTING STARTED -->\n## :man_technologist: :woman_technologist: Developer Getting Started\nThanks again for checking out CRASH! Please follow the steps below to get started and diving into the code in no time! Please sure sure you have all the <a href=\"#prerequisites-1\">Prerequisites</a> to have a smooth, unbuggy and fun experience!\n\n### Prerequisites\nYou will need the following libraries and/or software installed before getting to the fun!\n* [.NET Framework 4.8](https://dotnet.microsoft.com/en-us/download/dotnet-framework/net48)\n* [.NET Core 6](https://dotnet.microsoft.com/en-us/download/dotnet/6.0)\n* [Rhino 7.21+](https://www.rhino3d.com/download/)\n* [Visual Studio 2022](https://visualstudio.microsoft.com/vs/)\n\n### Prerequisites (MacOS)\nYou can also build and debug on MacOS using VS Code!\n* [Visual Studio Code](https://code.visualstudio.com/)\n* [Rhino 8 WIP](https://www.rhino3d.com/download/rhino/wip) is required on ARM machines.\n\n### Getting Source\n\nClone the repo\n   ```sh\n   git clone https://github.com/clicketyclackety/Crash.git\n   ```\n\n### Building\n\n#### Windows\nOpen Crash repository in Visual Studio:\n  1. Set Crash as startup project.\n  2. Build solution.\n  3. Drag and drop `Crash\\Crash\\bin\\Debug\\net48\\Crash.rhp` into an open Rhino window.\n  4. Re-open Rhino.\n  5. Happy debugging.\n\n#### MacOS\nOpen Crash repository in VS Code run build tasks `\u21e7\u2318B` in this order:\n  1. `buid-plugin`\n  2. `build-server`\n  3. `publish-server`\nFrom `Run and Debug` tab run `Run Rhino 8 WIP`\n\nRhino will launch in debug mode.\n\n## Docker\n\nNavigate to the Crash directory root. Run build to create the image.\n```powershell\ndocker build -t \"crash.server\" .\n```\nUse docker run to start the image\n```powershell\ndocker run -d -p 8080:80 --name crashy01 \"crash.server\"\n```\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- WORKFLOW EXAMPLES -->\n## Workflow Overview\nCrash works by allowing back & forth communication of clients with a central server to either send changes or receive changes. The server keeps record of a list of objects along with relevant attributes to allow the functionality required. One important distinction here is that the database/server will hold two types of objects; baked and ghost objects. Baked objects are drawn into the Rhino model while Non-Baked (called ghost here) objects are \"Pipeline\" objects. Communication between the client and database occurs in the form of invoking end points on either side and sending over \"Change\" objects that contain all the required information.\n\nThe following steps show a complete workflow of how the system works. For this example, there are 3 users (Bob, John, Mary) working on a central model called \"NYC Building 5\".\n1. Bob has a current Rhino model. He realizes the deadline is coming up and will need help from John & Mary.\n2. Bob initiates a shared model using Crash. This will create a server on his machine locally. Initially the server database is empty and Bob is the initiator so his machine would send all the current Rhino Geometry in his file to the server as a List of Change objects and invoke the appropriate command on the server.\n3. The server launches, receives data from the first initialization & populates its database with the list of objects received.\n4. John launches Rhino with an empty file. John then starts up Crash and selects to link to \"NYC Building 5\". The server instantly sends him all the list of objects in the database and invokes client side end points to re-create these objects in his model (both baked and ghost objects).\n5. Johns starts to draw new geometrical objects. After every action he performs (Add/Deleting/Updating), the client (John) invokes the appropriate command on the server and sends the required information as Change objects. Currently all new objects are considered ghost objects. All users see these new ghost objects in their views but are unable to select them or modify them.\n6. John is done creating new geometry and would like to \"commit\" these changes to other users. He presses the \"Im done!\" button. This invokes a command on the server to convert all objects owned/created by John and change their status from ghost to baked objects. This change is then pushed to all clients and they will see these objects turn into a baked object.\n7. Mary launches Rhino with an empty file. Mary then starts up Crash and selects to link to \"NYC Building 5\". The server instantly sends her all the list of objects in the database and invokes client side end points to re-create these objects in her model (both baked and ghost objects).\n8. Mary decides to select and delete one of the objects she sees. This will invoke the delete command on the server side and update the database.\n9. After the database is updated (on this deleted baked object), it invokes the delete function on all clients to remove this object from their Rhino model.\n10. All users now have the same objects in their model (baked and ghost objects).\n11. John selects an element and is thinking of what change he needs to do this object. As soon as he selects this object, his client machine would send the server and invoke the command to modify this object and mark it as locked. This would not allow any other user to select it until he presses \"Im done!\" button.\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- ROADMAP -->\n## Roadmap\n- [X] Local web server \n- [X] Rhino plugin (window)\n- [X] Deploy plugin to YAK\n- [X] Deploy webserver (Azure)\n- [ ] Version control\n- [ ] CI\n    - [ ] Unit tests\n    - [ ] Push to deploy\n- [ ] Expand Supported types\n    - [ ] Layers\n    - [ ] Object attributes\n    - [ ] Document settings\n- [ ] Authorization \n    - [ ] Rhino Accounts integration\n    - [ ] Permissions and access management\n\nSee the [open issues](https://github.com/clicketyclackety/Crash/issues) for a full list of proposed features (and known issues).\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- CONTRIBUTING -->\n## Contributing\n[Please see contribution guide](CONTRIBUTING.md)\n\n<!-- LICENSE -->\n## License\nDistributed under the MIT License. See `LICENSE.txt` for more information.\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- ACKNOWLEDGMENTS -->\n## Acknowledgments\nBig thanks to AEC Tech 2022 for arranging this event! Also we would like to thank McNeel for all their awesome work! This project has been a great collaboration of several great minds. Please check out other hackathon projects and future hackathon events hosted by [AECTech](https://www.aectech.us/).\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n[contributors-shield]: https://img.shields.io/github/contributors/clicketyclackety/Crash.svg?style=for-the-badge\n[contributors-url]: https://github.com/clicketyclackety/Crash/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/clicketyclackety/Crash.svg?style=for-the-badge\n[forks-url]: https://github.com/clicketyclackety/Crash/network/members\n[stars-shield]: https://img.shields.io/github/stars/clicketyclackety/Crash.svg?style=for-the-badge\n[stars-url]: https://github.com/clicketyclackety/Crash/stargazers\n[issues-shield]: https://img.shields.io/github/issues/clicketyclackety/Crash.svg?style=for-the-badge\n[issues-url]: https://github.com/clicketyclackety/Crash/issues\n[license-shield]: https://img.shields.io/github/license/clicketyclackety/Crash.svg?style=for-the-badge\n[license-url]: https://github.com/clicketyclackety/Crash/blob/master/LICENSE.txt\n[product-screenshot]: images/screenshot.png\n"
    },
    {
        "url": "https://github.com/pedrocortesark/dreamhopper",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Dreamhopper",
        "award": "BEST OPEN SOURCE HACK:",
        "summary": "No Summary Found",
        "content": "# Dreamhopper\n"
    },
    {
        "url": "https://github.com/vimaec/difference-engine",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Difference Machine",
        "award": "No Award Found",
        "summary": "Calculating differences between BIM models",
        "content": "<img src=\"/images/diff-eng-logo.png?raw=true\" alt=\"Difference Engine Log\" width=\"150\"/> <img src=\"/images/AECtech_Icon-wbg25.png?raw=true\" alt=\"AECTech Hackathon 2022\" width=\"150\"/>\n\n# Difference Engine\n\nThis repository hosts a tool for calculating differences between BIM models as part of the AECTech 2022 Hackathon. \nWritten in 180 lines of C# using .NET 6.0 and VIM API.\n\nThe Grasshopper scripts for loading visualizing the changes in 3D and as 2D graphs in Rhino, along with the web-app for hosting the visualization can be found at     \n[https://github.com/sophXmoore1/compute.rhino3d.appserver-1](https://github.com/sophXmoore1/compute.rhino3d.appserver-1).\n\n<img src=\"/images/difference-engine.gif?raw=true\" alt=\"Difference Engine Demo\" width=\"400\"/> \n\n## Presentation \n\nYou can [download the presentation as pdf](https://github.com/vimaec/difference-engine/blob/develop/difference-engine.pdf?raw=true) \nor [view it online](https://docs.google.com/presentation/d/e/2PACX-1vQACg-x1aFofd81DWELVLJY2yO-RP7jlrJ1bo4S-GNAuMFsRksXI2CM3l_f8fXLCX8usKlyR1CrVL-r/pub?start=false&loop=false&delayms=3000&slide=id.g14f5d6737d2_5_0). \n\n## How it works \n\nThe difference engine generates JSON files containing change records and OBJ files \nrepresenting the geometry which was added, removed, changed, resized, or moved. \n\nGrasshopper was used to load the deltas and geometry into Rhino, to display the geometry in 3D, to summarize and plot graphs in 2D, \nand to navigate through the deltas in time. \n\nA tool call the [Rhino Compute Appserver](https://github.com/dav-leon/compute.rhino3d.appserver) was modified and used to host Rhino and serve the data and visualizations over the web. \n\n## Performance\n\nWe were able to process 10 VIM files (total 100MB), originating from 10 Revit files (total 300MB) in 5 seconds, to produce the OBJ and JSON files representing the deltas (change sets).  \n\n## Team \n\nDifference Engine team:\n\n* Augustina Aboy\n* Ben Ferrer\n* Christopher Diggins\n* Matt Shelp\n* Nick Bowker\n* Nick Mundell\n* Sophie Moore\n\n## Requirements \n\n* Revit to VIM Exporter Plug-in [Get it for free here](https://cloud.vimaec.com)\n* VIM SDK [Contact us to get a copy](https://vimaec.com/contact)\n\n## Documentation / Source Code\n\n[Program.cs](https://github.com/vimaec/difference-engine/blob/develop/Program.cs)\n"
    },
    {
        "url": "https://github.com/just-ajs/DevHops",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "DevHops",
        "award": "No Award Found",
        "summary": "Visual programming interface with kanban for project management",
        "content": "![DevHops](./Assets/DevHops.png)\n\n# DevHops\nDevHops is a workflow and toolkit for organizing Rhino Grasshopper scripts with [Hops](https://developer.rhino3d.com/guides/compute/hops-component/) and [Kanban](https://en.wikipedia.org/wiki/Kanban_board) boards.\n\nThis tool was created as a part of the [AEC Tech 2022 Hackathon](https://www.aectech.us/)\n\n\n![AEC Tech Hackathon 2022](https://images.squarespace-cdn.com/content/v1/5d51be135134590001e45cf7/bf9a18f5-993c-44c1-b658-d0d77907f60a/AECtech_Banner_NYC-04.png?format=200w\n)\n\n## Introduction\nManaging Rhino Grasshopper scripts and workflows when working on complex, multi-year architectural projects is difficult, due to the size and complexity of Grasshopper definitions and procedural challenges when multiple computational designers work on the on the same script in parallel. \n\nThis project addresses this issue by proposing a workflow where  Grasshopper scripts are organized into multiple Hops components which are connected to a Kanban board for tracking project progression through work items.\n\n## Content\n| Content | App | Requirements |\n| ----------- | ----------- | ----------- |\n| DevOpsApp | NextJS 13 | NodeJS 16 and npm |\n| DevOpsBackEnd | NetCore 6 | Visual Studio 2022 and Microsoft SQL Server Express  |\n| DevHopsGh | Rhino 7 Grasshopper Plugin | Visual Studio 2022 and [Grasshopper template](https://marketplace.visualstudio.com/items?itemName=McNeel.Rhino7Templates)\n| DevHopsGhSamples | Rhino Grasshopper Samples | Rhino 7 Grasshopper\n\n## Getting Started\n### Grasshopper Plugin (DevHopsGh)\n1. Copy the .dll and .gha files from `C\\DevHops\\DevHopsGh\\Plugin` folder into your Rhino Grasshopper Components folder.\n2. Open in Visual Studio 2022 and build. \n\n### Backend (DevOpsBackEnd)\n1. Open in Visual Studio 2022 and run in debug mode to deploy the back-end.\n2. The backend will be running to `localhost:5296`.\n3. OpenAPI documentation is available on `http://localhost:5296/swagger`\n\n### Frontend DevOpsApp\n1. Run the NextJS webapp with `npm run start`\n2. The app is hosted on `localhost:3000`.\n\n## Attributions \n- Image: \"Hand drawn psychedelic groovy background\" by [Freepik](https://www.freepik.com/free-vector/hand-drawn-psychedelic-groovy-background_12277065.htm#query=groovy%20background%20wallpaper&position=2&from_view=keyword\")\n\n## Contributors\n- [mkosicki](https://github.com/mkosicki)\n- [jkamm](https://github.com/jkamm)\n- [just-ajs](https://github.com/just-ajs)\n- [andersrod](https://github.com/andersrod)\n- [cdriesler](https://github.com/cdriesler)\n"
    },
    {
        "url": "https://github.com/EmilPoulsen/ConfigAR.App",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "ConfigAR",
        "award": "No Award Found",
        "summary": "Connecting augmented reality with the super powers of parametric design and Grasshopper. Making it possible to visualize configurable designs in the real world using nothing else but your phone.",
        "content": "# ConfigAR.App\nUI Application for configar\n"
    },
    {
        "url": "https://github.com/EmptyBox-Design/project-vibe",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Project-Vibe",
        "award": "No Award Found",
        "summary": "Project-Vibe allows users to query anywhere in NYC to find what businesses are walking distance from the site.",
        "content": "# Project Vibe\n\n\n<img width=\"959\" alt=\"2022-11-08 09_24_28-Slack _ general _ betanyc\" src=\"https://user-images.githubusercontent.com/27181419/200589988-38f5f029-b813-4327-8596-24efaa2f42b4.png\">\n\nQuery anywhere in New York City to visualize the businesses within a 5 or 10 minute walk of the given location. Created at the [AEC Tech 2022 Hackathon](https://www.aectech.us/hackathon)\n\n# Tech Stack\n\n- Vue 3\n- Vite\n- Mapbox\n\n# Data\n\nOpen Street Maps were combined with [Legally-Operating-Businesses](https://data.cityofnewyork.us/Business/Legally-Operating-Businesses/w7w3-xahh/data) to create a robust open source data set of all businesses in NYC.\n\n## Team\n\n- Sandra Cai\n- Nanami Santa Cruz\n- Hailey Kim\n- Brandon Pachuca\n- Atharva Ranade\n- Tamaho Shigemura\n- Robert Wang \n\n\n## Slides\n\nPresentation given at the AEC Tech 2022 Hackathon\n\n[Slide Deck](https://docs.google.com/presentation/d/1y0ggiFxRDNsS-aNa9ue6APbfgcXSZKAYtHyrn-PLks8/edit#slide=id.g183c8cbdd58_1_26)\n"
    },
    {
        "url": "https://github.com/simpleSketche/GraFix",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "GraFix",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# GraFix\nGraFix is a Graph Neural Network based project started at AECTech Hackathon 2022. It is a collaborative effort by Omid, Yankun, Mostapha, Yuan-Tung, Mingbo, Sila, Taro, Alireza. The target is to fix 2d floor plan mis-alignment assuming the floor plan as a graph data structure, in which rooms are nodes and adjacencies are edges.\n![image](https://github.com/simpleSketche/GraFix/blob/main/Results/images/predict%20data.gif)\n\n## Probelm\nThe architecture 2d/3d models from architects are often \"broken\" and things are not precisely aligned. The time put in to manually fix the errors in the models usually taken about hours and sometimes even a week depending on the size of the model, and there is not a relatively good solution exsiting on market to optimize the fixing process. Therefore, we take on this challenge ourselves and use the power of graph neural network model to tackle this problem. If you are new to Graph or Graph neural network world, here are some good beginner friendly articles that make it easy to understand -> [Introduction to Graph Neural Network](https://distill.pub/2021/gnn-intro/) | [Understand Convolutions on Graph](https://distill.pub/2021/understanding-gnns/).\n![image](https://user-images.githubusercontent.com/71196100/200374021-3603563d-1031-4b5b-8175-b3792dca0a80.png)\n\n## Data Preparation\n![image](https://github.com/simpleSketche/GraFix/blob/main/Results/images/data%20generator.gif)\n![image](https://github.com/simpleSketche/GraFix/blob/main/Results/images/error%20data%20generator.gif)\nWe used the modular building generative model Yankun worked on in the past to generate the synthetic floor plan dataset. Each of the floor plan data could contain the number of boxes from 4 to 8, and we destroy the good \"floor plan\" to a broken state to train the machine to learn:\n1. What is bad floor plan?\n2. Which corner of the box to move in order to fix the \"floor plan\"?\n<br>\nGraph Neural Network is able to learn the buttom logic of the fixing logic from small batch (2000 data) of small floor plan training samples, and we can apply the training result on relatively larger \"floor plan\" that contains more boxes. This is greatly advantageous and separates Graph Neural Network from other neural network models.\n<br/>\n\n\n## Prediction\nThe result on a relatively larger floor plan(more boxes) is very promising given that we only trained the gnn model with 2000 synthetic simple data, and each training was so fast that it took about 5 minutes. The loss curve is going down and the learning curve is going up, both of the curves do not seem flattening, which gives us the hope that it would perform even better with much larger dataset mixed with realistic floor plan data.\n![image](https://user-images.githubusercontent.com/71196100/200372202-b45c4124-59f5-4d7d-b7a9-c71464247467.png)\n![image](https://user-images.githubusercontent.com/71196100/200382669-65b1a6c3-6b1a-4dee-9672-f573203f96f0.png)\n\n\n## Team\nThis can't be done without any one of this team, and it is an exciting beginning of something great!\nClick the images to visit their github pages!\n<br>\n[![image](https://user-images.githubusercontent.com/71196100/200363326-11f51cab-0df9-449f-a33d-57a6cbe175ee.png)](https://github.com/simpleSketche)\n[![image](https://user-images.githubusercontent.com/71196100/200363532-1a264ae7-0207-4ae9-a202-cc29fb18e8ca.png)](https://github.com/OmidSaj)\n[![image](https://user-images.githubusercontent.com/71196100/200363710-a56c2c3f-c4ba-4f32-9677-870368cbebc5.png)](https://github.com/ngulgec)\n[![image](https://user-images.githubusercontent.com/71196100/200364102-a190c599-6652-4fa3-93d3-2c52832a3021.png)](https://github.com/ton731)\n[![image](https://user-images.githubusercontent.com/71196100/200364698-8e3ebd56-0e7d-452b-b5b6-55ba217fc334.png)](https://github.com/mostaphaRoudsari)\n[![image](https://user-images.githubusercontent.com/71196100/200364997-2739efcb-7f11-4d38-a3a2-6b15dd6ba670.png)](https://github.com/MingboPeng)\n[![image](https://user-images.githubusercontent.com/71196100/200366117-041be235-8ba4-4378-9ce5-8738bff5903b.png)](https://github.com/tnarah)\n[![image](https://user-images.githubusercontent.com/71196100/200366292-2880c5af-66ee-49b3-be91-9a08f94b6b5b.png)](https://github.com/Memortal)\n\n## Synthetic Data Generation\nSynthetic data generator requires Rhinoinside python dependency to be installed, and you need to have Rhino license for it to run. However, feel free to use open-sourced geometry libraries and swap out Rhino dependency. The main geometric operations involved are:\n1. Find curve and curve intersection\n2. Create Point\n3. Create Vector\n4. Create Geometry plane to plane translation\n5. Create Curve from Polyline\n6. Create Polyline\n\n## Dependencies\nTo run this project, you would need:\n- python 3.7+\n- pytorch 1.12.2\n- pytorch.geometric 0.8.0\n- networkX\n\n\n"
    },
    {
        "url": "https://github.com/xyang920/Seism-sim.git",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Seism-Sim",
        "award": "No Award Found",
        "summary": "Using Unity and C# to develop a program to visualize game-effect building's time history response under an earthquake curve.",
        "content": null
    },
    {
        "url": "https://github.com/enmerk4r/pixeling",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Pixeling",
        "award": "BEST OPEN SOURCE HACK:",
        "summary": "No Summary Found",
        "content": "![Pixeling](https://user-images.githubusercontent.com/92090123/140653652-8ec32427-633b-417a-bf48-8609caeb9383.gif)\n\n## Pixeling\nPixeling is an experiment in pixel streaming that connects Rhino / Grasshopper to the Unreal Engine. This project has been developed by a team of collaborators for the 2021 AEC Tech Hackathon hosted by CORE Studio at Thornton Tomasetti.\n\n### Team Members\n* Edwin Bailey \n* Alfredo Chavez\n* Jeanne Li\n* Eesha Khanna\n* Brad Lei\n* Daniel Escobar\n* Amit Nambiar\n* Sergey Pigach\n* Jeroen Janssen\n\n### Rhino Bridge\n![](https://github.com/enmerk4r/pixeling/blob/main/Misc/Demo_1.gif)\n\n### Unreal Blueprint\n![](https://github.com/enmerk4r/pixeling/blob/main/Misc/image%20(23).png)\n\n### Grasshopper Converter\n![](https://github.com/enmerk4r/pixeling/blob/main/Misc/image%20(24).png)\n\n### Remote Pixel Streaming\nThe Unreal Project is deployed on a remote instance of AWS, enabling Pixel Streaming through the browser for multiple participants to call into the model vis, from any device!.\n![](https://github.com/enmerk4r/pixeling/blob/main/Misc/IOS.mp4)\n\nThere's a few steps to go through to set this up:\n#### Prerequisites:\n1. Create an [AWS account](https://aws.amazon.com/) with proper permissions and quota to launch the correct instances, etc., etc.\nWe noticed it works best with at least a `g4dn.xlarge`, but if you need more performance you might want to beef it up to a `g4dn.8xlarge` type. Make sure the EBS volume is large enough. Unreal Engine is big... We used a 150 Gb General Purpose SSD volume which works well.\n2. Launch the machine with Windows Server 2019\n3. Make sure on the security rules for the instance to open port 80 (we have 9999 open as well) for incoming traffic\n4. Set up an Elastic IP address and take note of the `Public IPv4 address`.\n5. The NVIDIA gaming drivers are not installed by default... Follow these steps otherwise Unreal Engine won't run: https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/install-nvidia-driver.html#nvidia-gaming-driver\n6. Install [Unreal Engine](https://www.unrealengine.com/en-US/) (at least v4.27.1)\n7. Install [Node.js](https://nodejs.org/en/) including the additional required packages - which will install a bunch of different stuff such as Python and [Chocolatey](https://chocolatey.org/)\n\n#### We are very grateful for these helpful resources:\n7. https://github.com/aws-samples/deploying-unreal-engine-pixel-streaming-server-on-ec2\n8. https://docs.unrealengine.com/4.26/en-US/SharingAndReleasing/PixelStreaming/PixelStreamingIntro/ \n9. Make sure you go through these steps carefully. For *section 2 - Start the Servers* for us that SignallingWebserver was actually saved under: `C:\\Program Files\\Epic Games\\UE_4.27\\Samples\\PixelStreaming\\WebServers\\SignallingWebServer\\platform_scripts\\cmd` and instead of running the `run.bat` file, on the AWS instance you want to run the `runAWS_WithTURN.bat` file.\n10. This will spin up the Signalling Server and you'll see the following in the console window:\n```\nWebSocket listening to Streamer connections on :8888\nWebSocket listening to Players connections on :80\nHttp listening on : 80\n```\n\n11. And you're good to go! Now you can start the Packaged Unreal Engine application with your project loaded (the amended shortcut to the .exe file - see the details in the link in step 8)\n\n12. On the AWS instance you can now browse to http://127.0.0.1 to see the model in your local browser (on the remote instance that is).\n13. And the rest of the world can now access the `Elastic IP address` you set up in step 4! **Hooray!**\n"
    },
    {
        "url": "https://github.com/MattBramante/BestFitAECHackAThon2021",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Best Fit",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/amitlzkpa/ar-points",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Spatial Scheduler",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/enmerk4r/Bonobo",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Bonobo",
        "award": "BEST OPEN SOURCE HACK:",
        "summary": "No Summary Found",
        "content": "# Bonobo\n A Grasshopper bridge for Blender simulations\n \n ![](https://github.com/enmerk4r/Bonobo/blob/main/Assets/Comp%202_2.gif)\n \n ## Credits\n Bonobo is a collaborative project developed as part of the summer 2021 AEC Tech hackathon at Thornton Tomasetti. The team includes [Sergey Pigach](https://github.com/enmerk4r), [Omid Sajedi](https://github.com/ssajedi), [Ardeshir Aliaskari](https://github.com/ardesh), [Congzheng Zou](https://github.com/CongzhengZOU) and [Sahil Tadwalkar](https://github.com/stadwalkar).\n\n![](https://github.com/enmerk4r/Bonobo/blob/main/Assets/Grasshopper.PNG)\n"
    },
    {
        "url": "https://github.com/EmilPoulsen/Hackuble",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Hackuble",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "![Hackuble gif](Resources/hackuble.gif) ![Hackuble icon](src/Hackuble.Web/wwwroot/icon.png)  \n*A hackable C# based scripting environment for 3D modeling running in the web browser.* \n\n## Background\nScript based 3D modeling software running in the web browser typically requires expertise in JavaScript (JS). This isn't a surprising fact, since web browsers are built specifically for interpreting and executing JavaScript code. However, while JavaScript is a great language, many professionals in the AEC industry (architecture, engineering and construction), are far more comfortable with programming languages such as C#. This is mainly because lots of CAD, BIM and analysis software have C# SDKs which have been widely adopted. That means that aspiring AEC professionals either have to pick up a new language and eco system (JS), or go back to desktop based 3D modeling software to achieve this. **Hackuble aims to bridge this gap.**\n\nHackuble is a generative 3D modeling environment built to write and execute C# code in the browser. Scripts can either be authored in the application, or brought in by loading compiled .NET dlls. The scripts can manipulate the 3D scene, such as adding objects. Each script becomes a button, which can be executed later on.\n\n## Context\nThis project was initially developed in the context of the [CORE studio Thornton Tomasetti](http://core.thorntontomasetti.com/) [AEC Summer Hackathon 2021](https://www.aectech.us/). The team consisted of the following people:\n- [Emil Poulsen](https://github.com/EmilPoulsen) [TT CORE Studio // Stockholm]\n- [Praneet Mathur](https://github.com/pm-Architect) [[ARPM Design and Research](https://arpmdesignandresearch.com) // India]\n- [Hanshen Sun](https://github.com/hanshenSun) [TT CORE Studio // New York]\n- [Yankun Yang](https://github.com/simpleSketche) [iBuilt Group // New York]\n- [Yushi Kato](https://github.com/YKato521) [Turner & Townsend // Japan]\n\nAmong other things, a major motivation for this project was the democratization of tools for design. The power to develop your own tools implies freedom and empowerment of creativity.\n\n## Features\n\n### Write, compile and execute C# scripts in the browser.\nHackuble comes with an in-browser scripting editor, where you can write and compile C# code to interact with the 3D viewport. Add your code to the `RunCommand` method and hit compile. You'll see a new button showing up in the toolbar which can be pressed to execute your code.\n\n![Hackuble gif](gifs/hackuble-01-write-commands.gif)\n*Writing, compiling and running scripts in Hackuble.*\n\n### Register command arguments to provide user input\nCommands can have input arguments, which will be presented as a modal to the user when running the script. Override the `RegisterInputArguments` method and add your command arguments with type, name, description and default value. Then use the `DataAccess` object inside of the `RunCommand` method to read the input values of the parameters.  \n\n![Hackuble gif](gifs/hackuble-02-input-parameters.gif)\n*Adding a command with custom inputs.*\n\n### Use the Hackuble SDK to build your own script libraries (dll) in Visual Studio\nHackuble offers an alternative way to add command buttons to the user interface. By importing the `Hackuble.Core` dll into your own dotnet standard library, you can write and compile your own Hackuble plugin and upload it to the web application at runtime. The dll is then parsed and all types inheriting from `AbstractCommand` will be registered and added to the user interface.  \n\n![Hackuble gif](gifs/hackuble-03-compile-plugin.gif)\n*Compiling and uploading custom Hackuble plugin dlls from Visual Studio.*\n\n## Getting started\n### Prerequisites\n* Latest version of VisualStudio 2019 [link](https://visualstudio.microsoft.com/downloads/)\n\n### Installation\n1. clone the repo\n\n```sh\ngit clone https://github.com/EmilPoulsen/Hackuble.git\n```\n\n2. Open `Hackuble.sln`\n3. Compile the `Hackuble.Examples` project.\n4. Set the `Hackbule.Web` project to start up and hit the debug button.\n5. Once the application is started, click on the \"Load Library\" button in the side bar. Locate the `Hackuble.Examples.dll` in the output from step 3 and select it.\n6. You should see buttons showing up in the sidebar.\n7. Clicking on one of those to test a command.\n\n## Create a script\nHackuble's system for adding scripts should look familiar to someone with experience with Revit/Rhino/Grasshopper tool development:\n\n1. Create a script by adding a new class and inherit from `AbstractCommand`.\n2. Write your script in the `RunCommand` override method.\n3. A `Context` object is injected into the `RunCommand` method, which you can use to interact with the scene, for instance adding objects to the scene. \n4. Each script can have a series of input parameters. These will be presented to a user through a modal in which they can specify values for the input parameters. Use the `RegisterInputArguments` override to add inputs.\n\nSee example below:\n```csharp\npublic class AddCubeWithColorCommand : AbstractCommand\n{\n    //Override there properties to configure the command.\n    public override string Name => \"Add Cube With Color\";\n    public override string Author => \"Emil Poulsen\";\n    public override string Description => \"Add a cuboid to the scene\";\n    public override string CommandLineName => \"cube-colors\";\n    public override string Accent => \"#FF96AD\";\n\n    //Here's where inputs are registered\n    public override void RegisterInputArguments(DataAccess dataAccess)\n    {\n        dataAccess.RegisterTextArgument(\"Color\", \"The color of the cube in Hex Format\", \"#FF96AD\");\n    }\n\n    //Here's the method that is called when the button is clicked.\n    public override CommandStatus RunCommand(Context context, DataAccess dataAccess)\n    {\n        //Use the DataAccess object to read the user provided inputs registered above.\n        string c = \"#ffffff\";\n        if (!dataAccess.GetData<string>(0, ref c))\n        {\n            return CommandStatus.Failure;\n        }\n\n        //Use the context object to add a cube with specified color to the view port.\n        context.AddCube(20.0, 20.0, 20.0, 0, 0, 0, c);\n        return CommandStatus.Success;\n    }\n}\n```\n\n## Tech stack\nThe following key technologies have been adopted in Hackuble: \n- [Blazor WebAssembly](https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor)\n- [Three.js](https://threejs.org/)\n- [CodeMirror](https://codemirror.net/)\n\nNote that Hackuble is a front-end only application, **meaning there is no need for a back-end**. This is possible through Blazor and WebAssembly! \n\n## Road map\n- Extend the functionality of the `Context` object to better reflect the state of the three.js scene.\n- Implement view port interaction to allow adding objects manually.\n- Web-based Visual Scripting Interface for Chaining Commands and Faster Parametric Design.\n- Integration + Interop with p5.js, ml5.js, and more.\n- Integration + Interop with ShapeDiver, Rhino.Compute and more.\n- One-click Deployment packages for local on-premise installation as well as cloud instances.\n- Multi-platform \u2018sister\u2019 environments for interop with the likes of Unity, UE4 and more.\n\n## License\n[MIT](LICENSE)"
    },
    {
        "url": "https://github.com/markhorgan/ganplan-webapp",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "No Title Found",
        "award": "BEST OPEN SOURCE HACK:",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/TheodoreGalanos/Layout5",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "No Title Found",
        "award": "BEST COLLABORATIVE HACK:",
        "summary": "No Summary Found",
        "content": "# Layout5\nA mixed-initiative, co-creativity layout generation tool for Rhino/GH, done during the AECTech 2020 Hackathon\n\n## Getting Started\n\n### Prerequisites:\nTo get everything working, set up a remote Rhino Compute server on an Amazon AWS EC2 Client.\nFollow the instructions here:\nhttps://github.com/mcneel/compute.rhino3d/blob/master/docs/deploy.md\n\nInstall Python on the remote server. Your best shot is Anaconda:\nhttps://www.anaconda.com/products/individual#windows\n\nInstall the folloiwng packages:\n- pyTorch:\nhttps://pytorch.org/get-started/locally/\nconda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n- Kornia:\nhttps://kornia.github.io/\nconda install -c conda-forge kornia \n(careful here, as the regular pip install kornia won't work with the BYOL we use...)\n- umap:\nhttps://umap-learn.readthedocs.io/en/latest/\nconda install -c conda-forge umap-learn\n\n\nMake sure you have the following Grasshopper plugins installed (also on the compute server - get them from Food4Rhino):\n- cPython\n- Ladybug/Honeybee (Legacy version)\n- Pufferfish\n- Human\n\nThen follow the Appserver set up:\nhttps://github.com/mcneel/compute.rhino3d.appserver/blob/main/docs/heroku.md\n\nand you're good to go!! :)\nours is here:\n\nhttps://layout5.herokuapp.com/example/\n"
    },
    {
        "url": "https://github.com/gener8-io/gener8",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Gener8.io",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "## Gener8.io\n\n### 1. We unit plans, to launch this project install [Node.js](https://nodejs.org/en/)\n### 2. Run the following command after installing Node.js `npm i`\n### 3. `npm start` to launch the browser.\n### 4. To learn about React visit https://reactjs.org/.\n\n___\n\nThis project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `npm start`\n\nRuns the app in the development mode.<br />\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.<br />\nYou will also see any lint errors in the console.\n\n### `npm test`\n\nLaunches the test runner in the interactive watch mode.<br />\nSee the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.\n\n### `npm run build`\n\nBuilds the app for production to the `build` folder.<br />\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br />\nYour app is ready to be deployed!\n\nSee the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.\n\n### `npm run eject`\n\n**Note: this is a one-way operation. Once you `eject`, you can\u2019t go back!**\n\nIf you aren\u2019t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.\n\nInstead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you\u2019re on your own.\n\nYou don\u2019t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn\u2019t feel obligated to use this feature. However we understand that this tool wouldn\u2019t be useful if you couldn\u2019t customize it when you are ready for it.\n\n## Learn More\n\nYou can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).\n\nTo learn React, check out the [React documentation](https://reactjs.org/)."
    },
    {
        "url": "https://github.com/enmerk4r/SmokingGAN",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Smoking GAN",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# SmokingGAN\nAn experimental framework for running ML Models inside the Grasshopper / Rhino environment\n\n## Attributions\nSmokingGAN is a Hackathon project for the 2020 AEC Tech Symposium organized by [CORE Studio](https://www.thorntontomasetti.com/core-studio) at [Thornton Tomasetti](https://www.thorntontomasetti.com)\n\nThis project has been a collaborative effort between [Mayur Mistry](https://github.com/Mistrymm7), [Sergey Pigach](https://github.com/enmerk4r), [Charlie Portelli](https://github.com/Crashnorun) and [Sergio Guindon](https://github.com/sguindon)\n\n**SmokingGAN borrows heavily from the following open-source projects:**\n\n**Fast Style Transfer**: https://github.com/lengstrom/fast-style-transfer\n\n**TF Monodepth 2**: https://github.com/FangGet/tf-monodepth2\n\n## Description\nSmokingGAN is an attempt at incorporating GANs into a Rhino / Grasshopper design workflow. The two major parts of the SmokingGAN are the Flask server exposing pre-trained checkpoints (This hackathon version currently serves [A Style GAN](https://github.com/lengstrom/fast-style-transfer) and a [Depth Map generator](https://github.com/FangGet/tf-monodepth2), but can be extended to work with any other pretrained checkpoints) and a Grasshopper plugin that accesses the Flask API and also provides functionality for converting images to meshes based on the depth information.\n\n![2x2](https://github.com/enmerk4r/SmokingGAN/blob/main/Assets/2x2.gif)\n![Rhino](https://github.com/enmerk4r/SmokingGAN/blob/main/Assets/Rhino.gif)\n\nThis is the basic architectural diagram showing the main components of the API:\n\n![Diagram](https://github.com/enmerk4r/SmokingGAN/blob/main/Images/Image%20GAN%20Flow%20Chart.png)\n \n ## Server Setup\n We recommend creating an Anaconda environment with **Python 3.7** (IMPORTANT: we've ran into serious issues with Tensorflow and Python 3.8)\n ```\n conda create --name your-env-name python=3.7\n conda activate your-env-name\n ```\n Install the necessary dependencies:\n ```\n conda install flask numpy imageio marshmallow matplotlib scipy pillow pandas\n pip install tensorflow==2.3.1\n pip install keras==2.4.3\n pip install tf_slim\n pip install flask\npip install marshmallow\npip install imageio\npip install matplotlib\n ```\nDownload the following checkpoint files:\n\n ***Style Transfer*** - https://drive.google.com/drive/folders/0B9jhaT37ydSyRk9UX0wwX3BpMzQ\n \n ***Depth Map*** - https://drive.google.com/drive/folders/0B9jhaT37ydSyRk9UX0wwX3BpMzQ\n \n Place them into `Flask/Checkpoints/StyleTransfer` and `Flask/Checkpoints/DepthMap` respectively.\n \n Run the server:\n ```\n cd GenerativeModeling/Flask\n python MainFrame.py\n ```\n## Grasshopper Setup\nOpen and build the **GenerativeModeling** solution from the `.NET` folder\n\nIn [Rhino's](https://www.rhino3d.com/) command line type in `GrasshopperDeveloperSettings`. In the dialog paste the path to the bin folder for the Visual Studio solution. Click ok and launch [Grasshopper](https://www.grasshopper3d.com/). You should see the SmokingGAN tab appear in the panel.\n\nHave fun:\n\n![Grasshopper](https://github.com/enmerk4r/SmokingGAN/blob/main/Assets/Grasshopper.PNG)\n![Flythrough](https://github.com/enmerk4r/SmokingGAN/blob/main/Assets/FlyThrough.gif)\n![Rhino Screenshot](https://github.com/enmerk4r/SmokingGAN/blob/main/Assets/RhinoScreenshot.png)\n"
    },
    {
        "url": "https://github.com/djsiroky/aectech2019-sketchto3d-frontend",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "SketchGAN",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": "# SketchGAN\n*a.k.a AECTech2019-sketchto3d-frontend*\n\n![](assets/Kanganru_Outback.png)\n\n## Introduction\nA web application that enables freehand sketching and attempts to transfer it to a \"rendered\" mode using a Generative Adversarial Network, while converting any preferred option to a 3d model representation.\nThis is the front-end application for the SketchTo3D pitch for [**AEC Tech 2019: Hackathon**](http://core.thorntontomasetti.com/aec-tech-2019-nyc/aec-tech-2019-hackathon/). It was developed by team **doodleGANg**.\n\nTeam Members:\n- Dan Siroky - HOK\n- Byron Mardas - F+P\n- Sounok Sarkar - HOK\n- Marios Tsiliakos -F+P\n\n## Getting Started\n\nJust fire-Up a web browser and go to this [address](http://157.55.139.151/app/index.html). Then you can just start sketching and the GAN will sort out the visual representation of your doodle. When happy with the results you can push the data to the backend application which will provide an approximated **Rhino** 3d model rendered on the UI.\n\n## Purpose\n\nTo re-establish freehand sketching as a design tool, enhancing it with automated 3dimensional content using the power of Generative Adversarial networks.\n\n## More\n\n### Installation\nNo need to install anything just run a local instance on your browser.\n\n### Dependencies\n- [p5.js](https://p5js.org/reference/#/p5.Vector/add)\n- [rhino3dm.NET](https://github.com/mcneel/rhino3dm)\n\n### Build and Test\nYou can clone the repo from [here](https://github.com/djsiroky/aectech2019-sketchto3d-frontend.git). Please contribute.\n\n### References\n\n### Work in Progress\n- Camera input - Get a photo of your sketch instead of sketching on the UI.\n- Conversion of Uploaded images to vectors\n- \n"
    },
    {
        "url": "https://github.com/cdriesler/building-ballot",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Building Ballot",
        "award": "BEST COLLABORATION:",
        "summary": "No Summary Found",
        "content": "# BLDG Ballot\n\n![building ballot logo](src/assets/logo.jpg)\n\n## Introduction\n\nAn iOS AR application that gathers stake holders opinions about designs and displays for design teams the selected options.\n\nThis repo contains code for the web application and the unity code to construct the iOS app for the [**AEC Tech 2019: Hackathon**](http://core.thorntontomasetti.com/aec-tech-2019-nyc/aec-tech-2019-hackathon/).\n\nTeam Members:\n\n- Luke Gehron - Payette - (Unity/ AR/ Team Lead)\n- Nat MacDonold - BuroHappold - (Unity/ AR)\n- Chuck Driesler - WeWork - (Web Development)\n- Arif Hanif - Affiliated Engineers, Inc. - (Web Development)\n- Samarth Gwalani - Meis Architects - (Design Thinker/ Market Analysis/ Concept Designer)\n- Riya Patel - Pei Cobb Freed & Partners - (Market Analysis/ Interior AR Layout)\n- Allie Bosarge - Shepley Bullfinch - (Market Analysis/Interior AR Layout and Finish Selection)\n- Xinye Lin - Independent Multidisciplinary Artists - ( Concept Design/ Video / Presentation )\n- Clifton Harness - Test Fit - (Building Options/Brand Curator)\n\n## Getting Started\n\nJust fire-Up a web browser and go to this [address](https://bldg-ballot.herokuapp.com/).\n\nThe Unity AR application is available for download from Google Drive [here](https://drive.google.com/open?id=1620VpHP6BCAv5XmQZXUqDi2XZmXjwOx1).\n\n### Technologies Used\n\n- UnityGLTF\n- Unity JSON.NET\n- Vue\n- Firebase\n- Revit\n- MapBox\n- ARKit\n- TestFit\n- Hypar\n"
    },
    {
        "url": "https://github.com/oliveregreen/regular",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Regular Espressos",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "![Regular Logo Smaller](https://user-images.githubusercontent.com/29973601/113752321-ba86ec80-9704-11eb-8447-44e7fc995e57.png)\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\n# Summary\nRegular is an open-source Revit plugin, designed to help users manage construction data. Our first tool, DataSpec, lets users define flexible format rules for Revit parameter values. Data can then be validated (and, if necessary, corrected) using an intuitive user interface. \n\n&nbsp;\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/29973601/114840351-a3b05c00-9dce-11eb-863b-2eb6a68dd0cd.gif\">\n</p>\n\n&nbsp;\n# Quick Links\n- [Installation](https://github.com/OliverEGreen/Regular/wiki/DataSpec-Installation)\n- [Getting Started](https://github.com/OliverEGreen/Regular/wiki/DataSpec-Getting-Started)\n- [Worked Examples & Video Tutorials](https://github.com/OliverEGreen/Regular/wiki/DataSpec-Examples)\n- [Dependencies](https://github.com/OliverEGreen/Regular/wiki/DataSpec-Dependencies)\n- [Sharing Rules](https://github.com/OliverEGreen/Regular/wiki/DataSpec-Sharing-Rules)\n- [Exporting Reports](https://github.com/OliverEGreen/Regular/wiki/Exporting-Reports)\n\n&nbsp;\n# The Big Idea\n\nIt is widely known that construction technology suffers from a lack of established data standards. Without robust, common data standards it becomes impossible to develop technology that escapes local practice and creates a global impact. To briefly restate the problems we face:\n\n1. Agreeing on optimal formats for data is hard: opinions are strong and will often differ between companies and sectors that have already invested in establishing their own internal processes.  \n2. Validating data created in line with any format specifications is a specialist task that too often falls to those who originally trained as architects, engineers, or project managers - not experienced data managers.\n3. The few standards we have are prone to frequent change. Moving the goalposts mid-way through a project often results in costly and unenjoyable data correction work. The risk of this happening is great enough to deter further standardisation from taking place.\n\nThe second and third problems above can be minimised by investing in programming skills. However, for AEC these remain in short supply.\n\nEnter DataSpec, designed to address the three problems above.\n\n- DataSpec gives users control over establishing data format standards at whatever level is right for them, be it project-specific, company-wide or industry-wide.\n- It provides an intuitive interface for rapid, automatic format validation against these rules. \n- It lets users easily adjust rules and rapidly revalidate against new standards, should these be introduced. \n\nDataSpec makes creating and sharing data standards easy, even for non-technical users.\n\n>Regular is an ongoing project. Future tools are currently being developed to help further reduce the cost of AEC data management.\n\n&nbsp;\n# How It Works\nBehind the scenes, DataSpec uses **regular expressions** - a technology commonly used by programmers to define rules for validating data that needs to follow a specific format, such as email addresses or phone numbers. Regular expressions (often shortened to 'regex') are an incredibly powerful tool, but one which requires specialist programming knowledge. Even programmers can find them difficult to work with!\n\nDataSpec works by abstracting away the complexities of regex behind an intuitive user interface, which lets non-technical users define rules for their data formats in plain English. Our goal is to \ud83d\ude4c *bring Regular Expressions to Regular Users* \ud83d\ude4c. \n\nData format rules are stored locally in a Revit document using the ExtensibleStorage API. These can be exported and imported between files using the .json file format, allowing for data format standards to be defined for a project, a company or even shared industry-wide. Those wishing to define a universal data format for, say, park benches are encouraged to pick up the mantle.\n\n&nbsp;\n## License & Data Safety\n\n- All data is processed locally on your machine, no external connections are made to anywhere or anything.\n- Regular is available using the highly-permissive [GNU Public License v3.0](https://github.com/OliverEGreen/Regular/edit/master/LICENSE).\n\n## Current Limitations\n- DataSpec can only validate text-based parameter values.\n- Conditional logic cannot be applied within rules - only relatively simple format logic can be used. \n- For simplicity's sake, DataSpec uses an intentionally-limited subset of the full regular expression syntax. AEC data formats tend to be relatively simple, so it's better to cover 99% of cases than push for 100%.\n\n## Contributing\nIf you'd like to help contribute to Regular, feel free to raise any issues, create pull requests and/or [message me on Twitter](https://twitter.com/Oliver_E_Green).  \nSee our [CONTRIBUTING.md](https://github.com/OliverEGreen/Regular/blob/master/CONTRIBUTING.md) file for more details. \n\n## Genesis\nRegular was started at the Thornton Tomasetti AEC Tech Hackathon 2019 in New York, presented by team \u2615 **Regular Espressos** \u2615 \n"
    },
    {
        "url": "https://github.com/nicoazel/arcrhino",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "ArcRhino",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "\n![ArcRhino](https://raw.githubusercontent.com/nicoazel/ArcRhino/master/Presentation%20Materials/ArcRhino_Name_Icon.PNG)\n\nAn AECTech 2019 Hackathon Rhino.Inside project for ESRI ArcGIS Pro\n\n[![Watch the video](https://github.com/nicoazel/ArcRhino/blob/master/Presentation%20Materials/Video%20frame.png)](https://vimeo.com/367573952)\n\n[Video](https://vimeo.com/367573952)\\\n[Download](https://tinyurl.com/arcrhino)\n\n## Description\nArcRhino makes a bridge between Rhino and ArcGIS by allowing you to easily take move information between both the applications.\\\nIt lets you use the the modeling and processing tools available in [Rhino](https://www.rhino3d.com/) with the GIS editing enviornment available in [ArcGIS](https://www.esri.com/en-us/arcgis/products/arcgis-pro/overview). It does this by using the experimental [RhinoInside](https://www.rhino3d.com/inside) project to create a new window in ArcGIS where you can use all of Rhino's tools and features (along with Grasshopper).\\\nIt converts the basic data types in ArcGIS (points, lines, polylines and polygons) into 3D geometry in Rhino and makes them available as attached metadata in Rhino.\\\n\\\nWe played with a few experimental projects like:\n- Generative Urban Design: Find the \"optimal\" location for a new park/outdoor theater.\n- Site Identification: Selecting Potential Sites for Analysis and Opportunity Weighting.\n- Building Use Analysis: For the selected plot, find if the nearby buildings are commercial.\n- Solar  Radiation Analysis: For the selected plot, find the best tree locations for optimal comfort.\n- Viewshed Analysis: Analysing areas that are visible from specific locations.\n- Outdoor Comfort Analysis(UTCI): For the selected plot, find the best tree locations for optimal comfort.\\\n\nThe projects showcased the strengths of the strong modeling and scripting environment in Rhino along with the specialized GIS management system in ArcGIS to create some iterative design development workflows.\n\n## Team\n\nAmit Nambiar\\\nEesha Khanna\\\nNico Azel\\\nRyan Welch\\\nSabrina Naumovski\n\n## Required Software\n\n- [Rhino 7 WIP](https://www.rhino3d.com/download/rhino-for-windows/wip)\n- [ArcGIS Pro](https://www.esri.com/en-us/arcgis/products/arcgis-pro/resources)\n- [Visual Studio >= 2017 15.9.17](https://visualstudio.microsoft.com/)\n\n## Resources\n\n- [Rhino.Inside](https://www.rhino3d.com/inside)\n- [ArcGIS Pro SDK](https://github.com/Esri/arcgis-pro-sdk/wiki/ProGuide-Installation-and-Upgrade)\n- [Rhino.Inside AECTech Workshop](https://github.com/mcneel/Rhino.Inside-Workshop)\n"
    },
    {
        "url": "https://github.com/preynoldson/punchboss",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "PunchBoss",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/LelandCurtis/daylighting-design-space",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Null Stack",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# daylighting-design-space\nDr. Mistrick's single-sided daylighting design space.\n"
    },
    {
        "url": "https://github.com/nadya/mechahopper",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "MECHAHOPPER",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/Brandoncyu/aechackathon2019",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "GitHub 1",
        "award": "BEST OPEN SOURCE: Stroll (",
        "summary": "No Summary Found",
        "content": "\n![first path](assets/screenshots/tree.png)\n\n# Stroll\n\nTT AEC Hackathon 2019 - Seattle\n\nThis is an app which helps people find the most nature-filled walks/paths to take thrughout the day in order to stimulate creativity and boost mental health.\n\nPathfinding is performed via Weighted Graph computation, with weights being given for characteristics such as proximity to parks, and amount of nature in the field of view.\n\n## Proof of Concept\n\nFor the proof of concept application, we were not able to complete the functionality of a walk being a \"loop\", but we do calculate and find the most nature-filled walk given the input parameters and start point.\n\n![first path](assets/screenshots/firstMap.png)\n\n## Developer Guide\n\nIn the project directory, you can run:\n\n### `npm start`\n\nRuns the app in the development mode.<br>\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nYou will also need to run the server seperately. The repo for the server can be found [here](https://github.com/Brandoncyu/aec-backend)\n\nThe page will reload if you make edits.<br>\nYou will also see any lint errors in the console.\n\n### `npm test`\n\nLaunches the test runner in the interactive watch mode.<br>\nSee the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.\n\n### `npm run build`\n\nBuilds the app for production to the `build` folder.<br>\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br>\nYour app is ready to be deployed!\n\n"
    },
    {
        "url": "https://devpost.com/software/eagle",
        "is_github_url": false,
        "is_devpost_url": true,
        "title": "Eagle",
        "award": "BEST COLLABORATION:",
        "summary": "No Summary Found",
        "content": "EAGLE\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nTeam\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nMission Control\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nInspiration\n\n\n50th Apollo 11 Anniversary Mission Control\n\n\nWhat it does\n\n\nMission Control\n - \nProject Eagle\n is about helping connect the data many firms already collect with a ML algorithm. The idea being proactive model maintenance ran off predictive analytics.\n\n\nProject Eagle has the goal to connect different open source project built in different hackathons. \nHox - Mission ControlAEC - Spectacles \n\n\nMissionControlAEC started with the AECHackathon at Facebook HQ from the work of the non-profit organization. (San Francisco Computational Design Users Group).\n\n\nMission Control is an HOK product released open source at the begging of 2019 for the Apollo 11 50th Anniversary of the Moon Landing. \n\n\nMission Control AEC is a web management tool that allows for better quality control of all our BIM Models without the need to open each model one by one, which saves an incredible amount of time, and assures the data integrity and performance stability in the environment. Furthermore, the tool can track the progression of every event and operation that happens in the Model. Thanks to the Forge and Design Automation API, Mission Control is also capable of performing the changes in the BIM environment.\n\n\nDuring the Hackathon, the EAGLE Team further developed Mission Control AEC to create a predictive model based on Time-Series that would help to not only forecast failures and corruptions, but also increase the liability of the models. The Proof of Concept developed during the weekend was strictly focused on monitoring views in relationship with the sheets. The goal was to integrate BIM Level 3 and Building Knowledge Modeling with Artificial Intelligence and Machine Learning so that they could quickly become part of the ecosystem and help the development of the project, forecasting and preventing errors and corruptions.\n\n\nHow we built it\n\n\nPython \nJSON\nJavascript\nGrasshopper\nOwl Plugins\n\n\nChallenges we ran into\n\n\nJson Parsing and deserialization \nCreate a tabular representation starting from a NoSQL export of a MongoDB\n\n\nAccomplishments that we're proud of\n\n\nThe training set was fairly accurate and we were able to display the results on the web\n\n\nWhat we learned\n\n\nClone the repository\nopen the terminal and run\n\n\n\"mongod\"\n\"npm run serve\"\n\n\ntest the new features\n\n\nWhat's next for EAGLE\n\n\nDesign Automation in Forge Working \n\n\nThe Team\n\n\nDesign Technology Specialists from WeWork, Nbbj, HOK, HMC and web developers \n\n\n\n\n\n\nBuilt With\n\n\njavascript\nkeras\npython\npython-package-index\ntensorflow\n\n\n\n\n\n\nTry it out\n\n\n\n\n\n\n\n\ngithub.com"
    },
    {
        "url": "https://github.com/dalefugier/RealDrawings",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Layout Hawk",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# RealDrawings\n\n<img width=\"128\" height=\"128\" src=\"https://github.com/dalefugier/RealDrawings/raw/master/Resources/final_hawk_256.png\">\n\n**RhinoDrawings** is an open-source, [Rhino](https://www.rhino3d.com/) plug-in project that was developed during the [**AEC Tech 2019 West Coast Hackathon**](http://core.thorntontomasetti.com/event/aec-tech-2019-seattle/) held in Seattle, Washington. The focus of the project and the team was to ease some of the pain in organizing and producing 2-D drawings in Rhino.\n\n### Team Members\n\n[Daniel Depoe](mailto:daniel.depoe@katerra.com), [Katerra](https://katerra.com/)\n\n[James Munns](mailto:jmunns@structurecraft.com> ), [StructureCraft](https://structurecraft.com/)\n\n[Dale Fugier](mailto:<dale@mcneel.com), [Robert McNeel & Associates](https://www.rhino3d.com/)\n\n[Mary Fugier](mailto:mary@mcneel.com), [Robert McNeel & Associates](https://www.rhino3d.com/)\n\n### Tools\n\n#### LayoutHawk\n\nThe initial tool attempts to solve the problem of Rhino's layout tabs. Layout tabs appear below Rhino's graphics area.\n\n##### Problem\n\nOnce you start creating multiple layouts, the tab control becomes unusable, as there are too many tabs to view. Thus, you are stuck having to click arrows to switch between layouts. If you have a lot of layouts, this involves a lot of clicking, and is very annoying. This user-interface is referred to a *papercut*.\n\n##### Solution\n\nThe team's solution was to developer a new `Layouts` panel. This panel shows all layouts in a easy-to-use list. Double-clicking on a layout item in the list activates the layout, thus completely eliminating the need for the layout tabs. The panel also provide additional functionality, such as creating new layouts, copying existing layouts, renaming layouts, deleting layouts, and more.\n\n### License\n\nCode licensed under the [MIT License](https://github.com/dalefugier/RealDrawings/blob/master/LICENSE).\n\n"
    },
    {
        "url": "https://github.com/pearswj/damagedogs",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "DamageDogs",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/RESThopper",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "RESThopper",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/alexzhou007/VIF",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Verify in Field (VIF)",
        "award": "BEST OPEN SOURCE:",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/mitevpi/thesaurus",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "theSAURUS",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# the-Saurus\n\n![Logo](Assets/logo2.png)\n\n## TT Hackathon 2018 Project\n\n**\"Autocomplete\" for [Dynamo](https://github.com/DynamoDS/Dynamo) based on statistical/machine learning models.** Please see the Project [**Presentation**](https://docs.google.com/presentation/d/1EypGPF-okLQuuB9NaoL1U_KaERHPjp_yM9HmP2DQKu0/edit?usp=sharing) Page for more details\n\n**Team:**\nAhmed Abbas\n[Petr Mitev](https://github.com/mitevpi)\n[Patrick Pease](https://github.com/patpease)\n[Konrad Sobon](https://github.com/ksobon)\n[Aaron Tang](https://github.com/QilongTang)\n[Varvara Toulkeridou](https://github.com/varvaratou)\n[Jasmine Wright](https://github.com/JasWright)\n\nThe very basic workflow:\n![Basic Workflow](Assets/workflowV1.gif)\n\nThe advanced workflow:\n![Basic Workflow](Assets/workflowV2.gif)\n\n## Data Models\n\n[**Training Data**](Data/Output/graphData.csv)\n\n| Node A Name                     | Node B Name                               | Node A ID                        | Node B ID                        |\n| ------------------------------- | ----------------------------------------- | -------------------------------- | -------------------------------- |\n| DSCore.List.Transpose@var[]..[] | DSCore.List.GetItemAtIndex@var[]..[]\\_int | b76189ba8c4a49dd875ddc88e806d5df | a2d2a3d30ff14eaaa120993bca904c53 |\n\n[**Custom Package Data**](Data/Output/packageData.csv)\n\n| GUID                                 | NAME                              | PATH                                                                                                            |\n| ------------------------------------ | --------------------------------- | --------------------------------------------------------------------------------------------------------------- |\n| ecdb3729-0de2-4c50-bdca-28fe881027a2 | Springs.FamilyInstance.ByGeometry | C:\\Users\\pmitev\\AppData\\Roaming\\Dynamo\\Dynamo Revit\\2.1\\packages\\spring nodes\\dyf\\FamilyInstance.ByGeometry.dyf |\n\n[**\"Hyper\"-Featurized Data (WIP)**](Data/Output/graphDataFeaturized.csv)\n\n| Node A Name | Node B Name | # Connections to Unique | # Connections Total | Custom? | Core? | ZT?  |\n| ----------- | ----------- | ----------------------- | ------------------- | ------- | ----- | ---- |\n| string      | string      | int                     | int                 | bool    | bool  | bool |\n"
    },
    {
        "url": "https://github.com/Crashnorun/GoRhinoGo",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "GoRhinoGo",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# GoRhinoGo\n\nThe goal of this project is to integrate Rhino inside with Unity 3D\n\n28 October 2018\n- Built for Oculus Go Headset + Unity Editor running on laptop\n- Rhino will launch when Scene is played and read the current scene\n- Headset users can connect to Windows \"mobile hotspot\", navigate scene, and create simple geometry\n- All geometry created is also created in Rhino\n\n[Join us on Slack](https://join.slack.com/t/gorhinogo/shared_invite/enQtNDY1OTU3MDUxMTA2LWM1ZGZiMzMzMjc3ZDUzNzkwNjE0NmQxMzcyMmQ1ZDJlMjYwNzNkYjVjNmYwOWNjMzczNjZjYzc1NmYyMzUyZjI)\n"
    },
    {
        "url": "https://github.com/amitlzkpa/SneakyCat",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "SneakyCat",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "\ufeff# SneakyCat\nSnugging data into your renders.\n\n## What is it?\nSneakyCat is a Grasshopper plugin that lets you embed data into images using a technique called [Steganograpgy](https://en.wikipedia.org/wiki/Steganography).  \nThe plugin takes data to be embedded and embeds it into the least significant digits of the pixel data in the image. The changes to the image are so small that it is difficult to perceive with human eyes.  \n\n## How to use?\n[Download](https://drive.google.com/open?id=1BteouK3rSwFebEHvYxN0cr-e2sKE1enR) and install the plugin as any [Grasshopper plugin](http://coder.the-bac.edu/?p=97).  \nThe `Purr` component embeds the data and `Hiss` component extracts it. You can optionally provide password to encrypt the data.  \nCheck out the example file to see how we embed and restor render settings into the render itself (secretly).  \n\n### Embed\n![Embed](./images/comp_embed.png)\n\n### Extract\n![Extract](./images/comp_extract.png)\n\n## Team\n- Amit Nambiar\n- Joseph Wagner\n- Vina Soliman\n- Leland Curtis\n- Zach Sickman\n\nThis project was made as a part of the [AEC Tech 2018 hackathon](http://core.thorntontomasetti.com/aec-tech-2018/aec-tech-2018-hackathon/).  \n"
    },
    {
        "url": "https://github.com/eertugrul/RhinoInsideSAP",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Stridulator",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/MingboPeng/AECTech18_RhinoInRevit/",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Take 'n Bake",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# Take 'N Bake\nCollection of Grasshopper components that facilitate the exchange of geometry between Revit and Rhino.Inside.\n\n\n# Take\nThe Take component references selected objects from the Revit model and reconstructs them in Grasshopper.\n\n\n# Bake\nThe Bake component translates Grasshopper geometry into Revit objects.\n\n## References\nhttps://github.com/mcneel/rhino.inside/tree/master/Autodesk/Revit\n\n## Team Members\n- Mingbo Peng\n- Suhail Sheth\n- Ramzi Jaber\n- Ricky Bagg\n- Tim Williams\n- Will Wang\n- Abhishek Bawiskar\n"
    },
    {
        "url": "https://github.com/hanshenSun/grassFlow",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Grassflow",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# grassFlow\nProject repository for 2018 AEC Hackathon \n"
    },
    {
        "url": "https://github.com/mm-wang/metashape",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Metashape",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "![](https://github.com/mm-wang/metashape/blob/master/Documentation/5%20Live%20Demo/ItWorks%2001b.gif)\n\n# metashape\ngeometry clustering of shapes based on trained features\n\nThe goal is to get a set of geometries and cluster them to see patterns in geometric shapes.\n\n## Initial Primitives\nAs a prototype, we developed a sample set of 16 elements that were categorized into cones, cylinders, spheres, and boxes.\n\n\n## Initial Clustering\nThis set was trained in scikit-learn and Accord.NET through dodo, lunchbox, owl. Owl fit our needs in predictive modeling most effectively.\n\n## Shape Analysis\nShape grammar has been notoriously difficult to quantify over the years manually, so machine learning is a great application of this\n\n### Consistent Geometry Analysis\nFirst, we take a dodecahedron to reduce polar biases and perform raycasting to determine vertex distances.\n\nWe also create a bounding box and then slice the building into upper, middle, and low slices as well as into levels describing terraces.\n\nAdditionally, we develop a contour and create a mesh to consistently calculate volume and area of the geometry.\n\n### Geometric Properties\nThe general properties we have focused on:\n- volume\n- surface area\n- centroids\n- orientation\n- ratios of properties\n\n## Machine Learning\nTo categorize the building shapes, we used a clustering algorithm that would automatically group buildings based on their geometric properties.\n\nFor clustering algorithms, we initially tried a regression classification to test plugins, but decided that [Owl](http://www.food4rhino.com/app/owl) was the best solution for our use case. We used the following features:\n\n- Area\n- Aspect Ratios\n- Centroid\n- Eccentricity\n- Orientation\n- Slice Area\n- Surface to Volume Ratio\n- Terraces\n- Vertex Mean Distance\n- Vertex Farthest Distance\n- Raycasting\n- Volume to Bounding Box Ratio\n- Volume\n\nThese provided us with enough features to distinguish differences between surrounding buildings.\n\n## Future Work\nWe hope to include further feature analysis for our machine learning algorithms.\n"
    },
    {
        "url": "https://github.com/EmilPoulsen/K2Engineering",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "K2Engineering",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "K2Engineering\n=============\n![K2Eng](images/K2Engineering.png)\n\nThis plugin contains a set of customised Kangaroo2 grasshopper components with the scope of calibrating a number of goals with regard to structural properties.\n\nThis is particularly useful for the analysis of form-active structures (including cablenets and gridshells) that are typically characterised by their large deformations when subjected to external loads. The underlying position-based dynamics implemented in the Kangaroo2 solver inherently deals with this non-linear behaviour. This means that both form-finding and analysis can be performed within the Grasshopper environment using K2 and K2Engineering.\n\n\nDependencies\n============\nInstall the following plugins:\n\n[Kangaroo2](http://www.food4rhino.com/app/kangaroo-physics) \n\n[Plankton](https://github.com/meshmash/Plankton/releases)\n\n\nDisclaimer\n==========\nEven though the plugin produces accurate and meaningful structural results, the author cannot be held responsible for the output and it should therefore always be used in combination with another finite element analysis package for validation and documentation.\n\n\nFeedback and enhancements\n=========================\nPlease report any bugs or requests for enhancement in the GitHub issue tracker.\n\n\nLicense\n=======\nThis software is licensed under the Apache 2 license: http://www.apache.org/licenses/LICENSE-2.0\n\n\nAcknowledgement\n===============\nThanks to Daniel Piker for the amazing Kangaroo2 plugin.\n\nThanks to James Solly for continuous dialogue and help improving the plugin.\n\nThanks to Format Engineers for a keen interest in applying the tool to relevant projects and thereby guiding the development.\n\nAlso thanks to Anders Deleuran, Gregory Quinn, Harri Lewis and Will Pearson for valuable inspiration and discussions."
    },
    {
        "url": "https://github.com/jlankitus/Dynamidi",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "DynaMidi",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# Dynamidi\nAec hackathon project ... input midi to dynamo \n"
    },
    {
        "url": "https://github.com/interopxyz/Aviary",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Aviary",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://github.com/RevitAirflowDesigner/RevitAirflowDesigner",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Duct People",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "\n# Revit add-in\n* User selects multiple possible shaft locations as nodes\n* User draws corridors with line\n* User clicks on \"Submit button\"\n\n# Dynamo script\n* Place VAV Boxes\n* Place ceiling diffusers in grid\n\n# Revit add-in\n* Generate a mesh of nodes and edge connections\n* Convert mesh into JSON\n* Convert geometry into lines for rendering in Python (either JSON or svg)\n* Save JSON to Google Drive\n\n# Python script\n* Read JSON\n* Calculate all possible paths\n* Calculate metrics (e.g. pounds of sheet metal, static pressure drop, etc.)\n* User views ductwork layout options\n* User selects preferred duct layout options\n* Python saves nodes for preferred duct layout option to JSON\n\n# Revit add-in\n* Import JSON\n* Create ductwork layout on nodes\n"
    },
    {
        "url": "https://github.com/ladybug-tools/honeybee-server",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Honeybee Server",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# This project is retired! For the latest version of honeybee docker images see [ladybug tools repository on docker hub](https://hub.docker.com/u/ladybugtools).\n\n# honeybee-server\n![honeybee-flying](https://user-images.githubusercontent.com/2915573/31865453-2591200a-b73d-11e7-9711-94a66604b6b9.gif)\n\n\nHonebee server is a work in progress to ease the depolyment of the honeybee on cloud! The project started at the [AEC Tech Hackathon 2017](http://core.thorntontomasetti.com/aec-tech-symposium-and-hackathon-2017/aec-tech-symposium-and-hackathon-2017-hackathon-info/). Try the single click deploy button below to start your honeybee-server on heroku.\n\n[![Deploy](https://www.herokucdn.com/deploy/button.svg)](https://heroku.com/deploy?template=https://github.com/ladybug-tools/honeybee-server)\n\n\n# Road map\nThis project is currently a proof of concept and still needs a lot of work to change to a stable product! We're planning to keep working on the project after the hackathon but there is no promise! Watch the page for the updates and let us know if you're interested to help!\n\nThank you for the great team to make this possible!\n![image](https://user-images.githubusercontent.com/2915573/31865331-7ae89882-b73b-11e7-9ee5-3e71b142b1df.png)\n\n\nYou can check our presentation slides [here](https://docs.google.com/presentation/d/1YlwquhsBBgxfumkY-J7UKnoCuar_B2suB9dp5pNW33M/edit?usp=sharing):\n[![image](https://user-images.githubusercontent.com/2915573/31865438-f49fee68-b73c-11e7-80ca-bf4534caa8e0.png)\n](https://docs.google.com/presentation/d/1YlwquhsBBgxfumkY-J7UKnoCuar_B2suB9dp5pNW33M/edit?usp=sharing)\n)\n"
    },
    {
        "url": "https://github.com/mkero-tt/Revilations",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Revilations",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "This is a file."
    },
    {
        "url": "https://github.com/anddoyoueverfeel/tthack2017",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Shuffle",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://aectechhack2017.devpost.com/submissions/79989-airflownetowrk_visualizer",
        "is_github_url": false,
        "is_devpost_url": true,
        "title": "Airflow Network Visualizer",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "Inspiration\n\n\nstruggling with designing natural ventilation design\n\n\nWhat it does\n\n\nto find out the best (or better) window openings for natural ventilation\n\n\nHow I built it\n\n\nusing DIVA ( or LB+HB) and visualizing result data\n\n\nChallenges I ran into\n\n\nHave no idea of using phython and hard to read result data and matching data with modelings\n\n\nAccomplishments that I'm proud of\n\n\nlogically I finished....\n\n\nWhat I learned\n\n\ntime management\n\n\nWhat's next for AirFlowNetowrk_Visualizer\n\n\nto make it as one component and \nuse colibri to find out best window opening size......\n\n\n\n\n\n\nBuilt With\n\n\nhappy-grasshopper"
    },
    {
        "url": "https://github.com/ladybug-tools/ladybugvizzz",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Ladybug Vizzz!",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": null
    },
    {
        "url": "https://devpost.com/software/revit-dynamo-json",
        "is_github_url": false,
        "is_devpost_url": true,
        "title": "Revit Dynamo JSON",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "Dynamo graph to write JSON\n\n\n\n\n\n\n \n\n\n\n\nJSON is the most common format of web data transfer. I explored ways of using that format to get data between Revit and Google Sheets.\n\n\n\n\n\n\nBuilt With\n\n\nc#\ndynamo\njson\nrevit\nrevit-dynamo\n\n\n\n\n\n\nTry it out\n\n\n\n\n\n\n\n\ngoo.gl"
    },
    {
        "url": "https://devpost.com/software/tango-go",
        "is_github_url": false,
        "is_devpost_url": true,
        "title": "Tango Go",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "The Mission\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nThe Intended usage\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nThe process\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nThe Team\n\n\n\n\n\n\n \n\n\n\n\nInspiration\n\n\nUse the Google Tango sensing technology to be able to link the digital and physical environments.\n\n\nWhat it does\n\n\nHow I built it\n\n\nThe goal is to have the Tango tablet sense the physical environment and send the data back to the modeling environment using Flux\n\n\nChallenges I ran into\n\n\nAndroid development, Unity connectivity with Google Tango\n\n\nAccomplishments that I'm proud of\n\n\nWhat I learned\n\n\nWhat's next for Tango Go\n\n\nFinish the project. \n\n\n\n\n\n\nBuilt With\n\n\nflux.io\ngrasshopper\nrevit\ntango-sdk\nunity"
    },
    {
        "url": "https://devpost.com/software/design-generator-82ulo4",
        "is_github_url": false,
        "is_devpost_url": true,
        "title": "Design Generator",
        "award": "",
        "summary": "No Summary Found",
        "content": "Design Generator\n\n\nDesign generator is a web interface to generate and evaluate design options.\nSee our \npresentation\n\n\nWrite-up by \nAmir Rezaei-Bazkiaei\n\n\nThe story begins with the creation of \nDesign Explorer (DE)\n tool of CORE studio. The goal with DE is to enable designers to exercise the impact of a broad range of design decisions on a range of goals or performance metrics. The tool gives ultimate flexibility to dissect the relationship between inputs and outputs but the design team still needs to go through rigorous modeling efforts to create a dataset to visualize. This has been the central part of an idea in the back of my mind, and as it turns out many other people\u2019s minds present at the Hackathon this year. After the announcement of ideas from multiple people of the group out team set out to design a web tool that can help design teams generate solution spaces with ease and accuracy.\n\n\nWhy is this needed:\n\n\nTo save time at early stages of design! The idea was to create a free, parametrized, online, easy-to-use tool that could be used by professionals to generate an early stage solution space within minutes to spark conversations and ideas. The common practice to answer such questions usually involves days of modeling the detailed geometry, internal inputs and systems to be able to shed light on early stage questions. By the time the sustainability consultant puts all of that together there is a good chance that the design team has moved on with their decisions or decisions are made in silos with limited feedback. In the best-case scenario that a consultant is involved, it usually takes a lot of time to model the geometry, break down the building complexity and run analyses to get key performance metrics out for a large solution space.\n\n\nDesign solution comparisons and selections are usually high level conversations that are commonly overruled by cost or preferences at early stage design meetings. Comparing design options through detailed modeling is an intensive effort that has little ROI on the consulting services provided. In other words, detailed and rigorous modeling, including various QA and fact checking, are better to be reserved for later stages of design where aggressive goals could take advantage of the fees. It is important to remember that the idea of the online tool wasn\u2019t to replace the consulting services but rather to serve as a tool to start basic design conversations such as HVAC system selections and envelope choices.\n\n\nHow can this work:\n\n\nThis project looked at generating a large dataset or a fully parametrized model that can be used for all climate zones and space types to come up with initial key performance metrics (energy, peak loads, daylighting, etc.) that can be used at early stages of design. This tool would enable designers to filter through a large dataset or select a set of inputs representing their buildings (or portions of it) and get instant feedback on key building performance metrics without the need to create a detailed model. A fully parametrize shoebox model was used to represent the geometry.\n\n\nThe underlying assumption to aim at producing such tool is that the energy use of a building is primarily driven by three main factors: 1) building architecture and ambient conditions 2) internal loads, space programming and use profiles and 3) HVAC systems.\n\n\nTheoretically, for a specific building type, HVAC system, and envelope properties, there should be a relatively linear relationship between the energy use and the size of the building. That is the premise that makes an index like EUI (kBtu/ft2) a useful metric while comparing different buildings. Size in this context is a metric that captures the ratio of exterior exposure to interior volume as well as the average building internal loads accounting for diversity in the space programming. The PassiveHouse standard for example looks at the exposed exterior area of building (A) to the enclosed volume (V) as an initial compactness metric. This needs to be coupled with a similar metric that captures the ratio of different space areas relative to the main building occupancy so that the internal gains can be normalized and scaled with simple building area inputs. The user then only needs to input area information from the actual project.\n\n\nIf the geometry and architectural features can be simplified with mostly area and dimension inputs then a broad range of different thermal properties, climatic conditions and HVAC options can be evaluated with the help of automating scripts. There are many other factors embedded in this simplification that need to be vetted. To name a few:\n\n\n\n\nPerimeter to core area ratio representing actual building\n\n\nWindow-to-wall ratio\n\n\nShoebox model boundary condition and scalability\n\n\nOA requirement rates based on areas and delivery method\n\n\nCommon HVAC system efficiencies and their dependency on full-size geometry\n\n\n\n\nWhat are some challenges:\n\n\nUsing a shoebox approach can be beneficial to parametrize the model more easily but can also introduce the potential of missing key architectural and mechanical factors that will be present in a full-scale model. Factors such as the impact of multi-story building boundary conditions and the interactions between HVAC systems in a full-scale model versus a shoebox model come to mind. List of potential challenges:\n\n\n\n\nPlant loop implications for HVAC systems in the shoebox model versus full-scale\n\n\nAir mixing at the air loop level between multiple zones is limited in a shoebox model\n\n\nOA flow rates will need to be input separately for perimeter and core areas to represent main building occupancy and other space types\n\n\nInternal load diversity impact on the HVAC energy consumptions may not be easily realized\n\n\nInitial area proportions need to be realistic to represent the programming of the building\n\n\nArchitectural elements such as shading devices can be more easily incorporated and parametrized in the shoebox model but will need to be translated to well represent the real-world shading potential\n\n\n\n\nWhere things are now and what needs to be done:\n\n\nThe image below shows the conceptual workflow of how the tool works. The team was able to create the \nweb interface\n, identify the initial list of input and output parameters, and create the analytical backbone in Grasshopper (Honeybee/Energyplus + Ladybug) to generate energy and daylight outputs. The original idea was to create a large database that the user can access but it was concluded that the design space will become too large too fast to cover a reasonable range of inputs for all or even a portion of variables. In my opinion, the tool will ideally host the simulations engines on a server that has a reasonable storage capacity to store the outputs generated for a range of variables that the user enters via the web interface. The automation part that needs to be figured out is how and where to host the simulation engines and outputs, and how to parse the outputs to the design explorer website.\n\n\nA few informative conversations during the development were centered on the idea that the modeling tools are not necessarily equipped with the engineering design logic and rule of thumb values that designers use in practice. These rules of thumb usually come from the physical limits of particular HVAC equipment at zone level to meet the heating/cooling loads. For this online tool to truly become beneficial, it is required that more HVAC level inputs are exposed at the web interface level. The user should be able to have access to HVAC component inputs such as zone and plant level efficiencies, fan and pump pressure drops, design temperature differentials, etc. and be able to assign different HVAC systems to different orientations of the building.\n\n\nThe \u201cautosizing\u201d functionality of Energyplus, and any other energy modeling software for this matter, can also be misleading and one of the most overlooked inputs in the energy modeling process. It is common practice to design efficient systems like radiant floors or chilled/heated beams for a specific heating/cooling capacity limit which is based on the practical aspects of how these systems can meet perimeter loads. Radiant floors for example operate best for cooling at around peak cooling loads of 15 Btu/hr.ft2 (this number may vary slightly depending who you ask). The autosizing assumption in Energyplus though usually is that the entire floor is covered with in-floor tubes that have maximum water flow rates available to them to meet the loads. In practice, a designer may only design the radiant floor capacity up to 15 Btu/hr.ft2 of the peak and meet the rest of the loads with a supplemental equipment such a fan-coil units (FCU) knowing that a radiant system may not be adequate. What is overlooked if the unlimited radiant floor capacity is assumed is the upfront cost to install and potential additional cost to operate the supplemental FCUs which is typically something an energy modeler will not double check..\n\n\nThis tool also needs to take key architectural and HVAC inputs by orientation so that the shoebox model can be used to answer questions that are dependent on different fa\u00e7ade orientation. One possible alternative to speeding up the simulation times is using surrogate models or machine learning algorithms in conjunction with the Energyplus engine runs.\n\n\nLooking forward to hearing your thoughts.\n\n\nList of identified inputs:\n\n\n\n\n# of Floors\n\n\nTotal building area\n\n\nAspect Ratio\n\n\nPerimeter Depth\n\n\nOrientation\n\n\nFloor to Floor height\n\n\nWindow Wall Ratio (%)\n\n\nWindow Height\n\n\nSill Height\n\n\nShading overhang depth\n\n\nInfiltration\n\n\nWall Assembly Type (steel framed vs. mass)\n\n\nRoof Assembly Type (steel framed vs. mass)\n\n\nWall R-value\n\n\nRoof R-value\n\n\nGlazing U-factor\n\n\nGlazing SHGC\n\n\nGlazing VLT\n\n\nOutside air (Core)\n\n\nOutside air (Perimeter)\n\n\nInternal Load (Core)\n\n\nInternal Load (Perimeter)\n\n\nHeating Setpoint\n\n\nCooling Setpoint\n\n\nHVAC System\n\n\n\n\nKey performance metrics:\n\n\n\n\nEnergy use intensity (EUI)\n\n\nEUI breakdown\n\n\nPeak heating and cooling loads for each zone\n\n\nPlant equipment sizes or loads\n\n\nDaylight factor\n\n\nUpfront equipment cost\n\n\nOperational energy cost\n\n\n\n\nHow we built it\n\n\nThe current stack uses three.js, d3.js, Twitter bootstrap, and the google drive API for the interface.  We used Rhino + Grasshopper + Honeybee to generate the energy simulation result database.\n\n\nChallenges we ran into\n\n\n\n\nThe google drive API is tricky to navigate - we are still sorting how to make this an entirely client-side app without hitting the security restrictions of cross-origin requests.\n\n\nIntegrating multiple sliders from Twitter bootstrap with Three.js proved difficult, and still isn't functioning quite right in the app.\n\n\n\n\nWhat's next for Design Generator\n\n\nWe need to get the interface working, and full link the energy simulation result data.  The existing tool is a proof-of-concept, with all the parts built, but not fully linked yet.\n\n\nTeam members\n\n\nAn-lei Huang, Anton Szilasi, Byron Mardas, James McNeill, Leland Curtis, Matt Dahlhausen, Mostapha Sadeghipour Roudsari. \n\n\n\n\n\n\nBuilt With\n\n\nbootstrap\nd3.js\nenergyplus\ngoogle-drive-api\ngrasshopper\nhoneybee\nopenstudio\nrhino\nthree.js\n\n\n\n\n\n\nTry it out\n\n\n\n\n\n\n\n\ndesign-generator.github.io"
    },
    {
        "url": "https://github.com/sasakiassociates/revit-3d-print",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "3D Print and Revit",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# revit-3d-print\n\n## Requirements\n\n- Windows v7, v10\n- Autodesk Revit v2016, v2017\n- [Dynamo](http://dynamobim.org/download/) v1.2.x, v1.3.x\n\n## Installing\n\n- [Git](https://git-scm.com/download/win)\n- Python\n\t- [Python](https://www.python.org/downloads/)  v2.7.x\n\t- [Pillow](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pillow) v3.4.2\n- .svx to .stl (Java)\n\t- [code](https://github.com/AbFab3D/AbFab3D), [post](https://abfab3d.com/svx-format/)\n\t- [JDK](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) v8\n\t- [Apache Ant](http://ant.apache.org/bindownload.cgi)\n- setup Environment Variables: adjust the directory based on your downloaded location/version\n\t- `JAVA_HOME`: `C:\\Program Files\\Java\\jdk1.8.0_101`\n\t- `ANT_HOME`: `C:\\Program Files\\apache-ant-1.9.7`\n\t- `PATH`: append to the end\n\t\t- `C:\\Python27`\n\t\t- `C:\\Python27\\Scripts`\n\t\t- `%ANT_HOME%\\bin`\n\n## Layout\n\n\t/archive                 ... archive Dynamo scripts\n\t/script                  ... python script\n\t/image                   ... empty output folder\n\t\t/origin              ... original Section View .png images\n\t\t/invert              ... invert .png images \n\t\tmanifest.xml         ... .svx configuration\n\t\tmodel.svx            ... .svx model\n\tREADME.md                \n\tdynamicSectionView.dyn   ... main Dynamo script\n\n## How to\n\n- create View Template in Revit\n- setup parameters in `dynamicSectionView.dyn`\n- create `image` folder\n- run `dynamicSectionView.dyn`\n- get `model.svx`\n\n## Team\n* [Yueying Cui][1]\n* [Chris Winkler][2]\n* Youngjin Lee\n* Ken Goulding\n\n## Reference\n\n[1]: mailto:ycui@sasaki.com\n[2]: mailto:cwinkler@sasaki.com\n"
    },
    {
        "url": "https://devpost.com/software/benmap-ey817q",
        "is_github_url": false,
        "is_devpost_url": true,
        "title": "BEnMap",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "Inspiration\n\n\nGreen shaming/celebrating buildings in the city of Boston based on their energy use\n\n\nWhat it does\n\n\nFilters and displays information about the buildings that have been reported.\n\n\nHow we built it\n\n\nCleaned data from the public repository listed at \nhttps://data.cityofboston.gov/\n to more accurately represent buildings and ignore outliers.\nFiltered the data with \n\n\nWhat's next for BEnMap\n\n\nMore cities!\n\n\n\n\n\n\nBuilt With\n\n\ncss3\nhtml5\njavascript\n\n\n\n\n\n\nTry it out\n\n\n\n\n\n\n\n\nladybug-analysis-tools.github.io"
    },
    {
        "url": "https://github.com/DOCQR/docqr.github.io",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "docQR",
        "award": "BEST OVERALL HACK:",
        "summary": "No Summary Found",
        "content": "# docqr.github.io\nView Building Construction Docs Online via QR Codes\n\n#Problem Statement:\n##Demystiphy 2D!\n\nBIM software such as Revit and Archicad have been designed to generate a 3D building model, to then produce 2D [paper] drawings.\n\nOnce printed, the sections displayed in 2 dimensions might not entail all of the detail necessary to understand the building. \nDOC-QR is a tool that aims to visuals those sections, shown in 2D architectural drawings, as trimmed sections of the 3D Revit model, in a web browser.\n\nThe project was proposed by Jonatan Schumacher [here](http://aec-technology-hackathon-2015.devpost.com/forum_topics/5187-3d-model-viewer-to-accompany-2d-drawings) - check out the sketch below for the rough idea.\n![alt tag](https://raw.githubusercontent.com/DOCQR/web-viewer/master/files/documentation/JS_HackathonProposal.jpg)\n\nThis tool currently consists of two parts: \n- node.js application\n- Revit Plugin\n\nThe web application allows users to create an account, and to create 'Projects'. \nThe Revit plugin, which communicates with the web app, prompts the user to log in. Once logged in, one can select one of the user's projects, and publish 3D sections of all drawings in the Revit model. \nIn the same process, the Revit app also places QR codes next to all views on the sheets, and uploads the 3D models to the webapp, where they can be retreived at the URLs stored in the QR code.\n\n[Video of Revit Demo] (https://youtu.be/cHrULgEkMXw)\n"
    },
    {
        "url": "https://github.com/HydraShare/hydra",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Hydra",
        "award": "BEST HACK USING EXISTING APPLICATIONS:",
        "summary": "No Summary Found",
        "content": "# hydra\n[Hydra](http://hydrashare.github.io/hydra/) is a web platform to share your example files from Grasshopper and Dynamo.\n\nThe project is inspired by http://bl.ocks.org/\n\nHydra is started at the [2015 AEC TECH Hackathon](http://aec-technology-hackathon-2015.devpost.com/) and was one of the two winners for best collaboration and opensource development.\n\n![Screenshot](https://pbs.twimg.com/media/CP7wdEDWcAAWph_.jpg:large)\n\nHydra started by: [Chris](https://github.com/chriswmackey), [Keith](https://github.com/alfarok), [Matthew](https://github.com/mdahlhausen), [Mostapha](https://github.com/mostapharoudsari)\n\n## Don't share files, share Hydras!\n![Screenshot](https://github.com/HydraShare/hydra/raw/installation/Imgs/Concept_Chart.jpg)\n"
    },
    {
        "url": "https://github.com/pix3lot/Slackit",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Slackit",
        "award": "BEST COLLABORATION/OPEN SOURCE:",
        "summary": "No Summary Found",
        "content": "## Slackit\nSlackit is a plugin developed for Revit that enables the software to communicate with team members via Slack. This allows the model to alert users if something goes awry and giving a programmable interface for model management and maintenance. \n\n## Installation\nFor easy installation download the zip file for your Revit version. Unzip the contents into the appropriate Revit addin location:\n`C:\\ProgramData\\Autodesk\\Revit\\Addins\\[YEAR]`\n\n## Usage\nRun the plugin and enter the token to your Slack site. Select the Slack channel you want the Revit model to post to and save the settings. Sync with central and watch the fun. \n\n## Current function\nMessages are sent to a specified channel (no groups or DMs yet)\n\nRandom gifs (via Giphy) are embedded into the messages by keywords search.\nGIF can be large, small, or turned off\n\nMessages included so far:\n* Synch to Central started\n* Synch to Central completed\n* Central model was opened\n* User closed the file without synching to central\n* File Size is > 300MB\n* Pinned Element Tracking\n\nScreenshot button sends full screenshot to project channel\n\n## Future development\n\nMisc\n  * Include groups and DMs\n  * Post messages to/from Revit ribbon\n  * Attach to database to track project file health long term\n  * OAuth instead of token\n\nMore messaging options \n  * Open/sync takes too long\n  * Audit type issues (revit warnings & errors, non-standard practices)\n  * Imported DWG files\n"
    },
    {
        "url": "https://github.com/danielinocente/application",
        "is_github_url": true,
        "is_devpost_url": false,
        "title": "Skinventor",
        "award": "No Award Found",
        "summary": "No Summary Found",
        "content": "# SKINVENTOR-EXE\n\nExecutable Application\n\nThank you for downloading this application. It was written to work directly with Rhino + Grasshopper and Nathan Millers LunchBox Tools. There are additional example files provided for use with this application and they can be downloaded on the apps webpage. \nSystem Requirements\n\nMust have Autdesk Inventor Installed along with the latest version of Rhinoceros and Grasshopper. This workflow utilized the latest version of LunchBox for Grasshopper (http://provingground.io/tools/lunchbox/) but can also be used with LunchBox for Dynamo.\n\n1. Open Rhino Example File\n\n2. Run Grasshopper (Verify that latest version of Grasshopper and Lunchbox are Installed)\n\n3. Export the XML File\n\n4. Run SKINVENTOR Application and select your XML File (Keep refresh dialogue open to regenerate any updates to the XML)\n\n5. Instantiate Elements within Inventor\n\n6. Please share any insights or examples of how you have used this application.\n"
    }
]